{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "obpV29rs4l7r",
    "outputId": "57d36730-6338-4273-d4d8-4d9f11fbbf70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting matchms\n",
      "  Downloading matchms-0.18.0-py3-none-any.whl (109 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.6/109.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from matchms) (3.7.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from matchms) (1.22.4)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from matchms) (3.1)\n",
      "Collecting pickydict>=0.4.0\n",
      "  Downloading pickydict-0.4.0-py3-none-any.whl (6.1 kB)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from matchms) (4.9.2)\n",
      "Requirement already satisfied: numba>=0.47 in /usr/local/lib/python3.10/dist-packages (from matchms) (0.56.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from matchms) (4.65.0)\n",
      "Collecting deprecated\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from matchms) (2.27.1)\n",
      "Collecting pyteomics>=4.2\n",
      "  Downloading pyteomics-4.6-py2.py3-none-any.whl (235 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.1/235.1 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sparsestack>=0.4.1\n",
      "  Downloading sparsestack-0.4.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from matchms) (1.10.1)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.47->matchms) (0.39.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.47->matchms) (67.7.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->matchms) (1.14.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matchms) (4.39.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matchms) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matchms) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matchms) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matchms) (8.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matchms) (23.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matchms) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matchms) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->matchms) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->matchms) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->matchms) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->matchms) (3.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->matchms) (1.16.0)\n",
      "Installing collected packages: pyteomics, pickydict, deprecated, sparsestack, matchms\n",
      "Successfully installed deprecated-1.2.13 matchms-0.18.0 pickydict-0.4.0 pyteomics-4.6 sparsestack-0.4.1\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting rdkit\n",
      "  Downloading rdkit-2022.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (8.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.22.4)\n",
      "Installing collected packages: rdkit\n",
      "Successfully installed rdkit-2022.9.5\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pickle5\n",
      "  Downloading pickle5-0.0.11.tar.gz (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.1/132.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: pickle5\n",
      "  Building wheel for pickle5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pickle5: filename=pickle5-0.0.11-cp310-cp310-linux_x86_64.whl size=256426 sha256=de0aac5538459c20f71d461c4285175c564d10ba512c1d2e96bfd9e2f497f460\n",
      "  Stored in directory: /root/.cache/pip/wheels/7d/14/ef/4aab19d27fa8e58772be5c71c16add0426acf9e1f64353235c\n",
      "Successfully built pickle5\n",
      "Installing collected packages: pickle5\n",
      "Successfully installed pickle5-0.0.11\n"
     ]
    }
   ],
   "source": [
    "!pip install matchms\n",
    "!pip install rdkit\n",
    "!pip install pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vsQ3LiWj4yKf"
   },
   "outputs": [],
   "source": [
    "from rdkit.Chem import AllChem\n",
    "from matchms.importing import load_from_msp\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "import matchms\n",
    "from matchms import Spectrum\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from rdkit.Chem.rdmolops import GetAdjacencyMatrix\n",
    "\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ulW_xC0WH6A9",
    "outputId": "ef3cb684-a34b-4074-82b5-b77b3e1e5a59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%history\n",
      "%history\n",
      "%history\n",
      "%history -c\n",
      "%history\n",
      "ls $(ipython locate)/profile_*/*.sqlite\n",
      "%history\n",
      "%history\n"
     ]
    }
   ],
   "source": [
    "%history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6oqXUIqDH8dS"
   },
   "outputs": [],
   "source": [
    "BASE_DIRECTORY = \"/content/drive/MyDrive/NIST_ECF\"\n",
    "os.chdir(\"/content/drive/MyDrive/NIST_ECF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4L4_75UK4yMy"
   },
   "outputs": [],
   "source": [
    "OUTPUT_SIZE = 1000\n",
    "INTENSITY_POWER = 0.5\n",
    "\n",
    "EMBEDDING_SIZE = 2000\n",
    "# depends on fingerprint generation\n",
    "INPUT_SIZE = 2**10\n",
    "MASS_SHIFT = 5 \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2nSJtiG7ICDF"
   },
   "outputs": [],
   "source": [
    "with open(\"/content/drive/MyDrive/NIST_ECF/Preprocessed_test_pow_ECF_small.output\", 'rb') as handle:\n",
    "    data_list_test  = pickle.load(handle)\n",
    "\n",
    "# with open(\"/content/drive/MyDrive/NIST_ECF/Preprocessed_train_pow_ECF_small.output\", 'rb') as handle:\n",
    "#    data_list_train  = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XUcG7nEghaqM",
    "outputId": "a94e2984-4756-488f-d1bd-d9187f6e1844"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28082, 112709)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_list_test), len(data_list_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ftf_a-X2IFJ1"
   },
   "outputs": [],
   "source": [
    "class ECFDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        input_tensor, molecular_weight, output_tensor = self.data[index]\n",
    "\n",
    "        return input_tensor, molecular_weight, output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pjup_IfcIHvL"
   },
   "outputs": [],
   "source": [
    "NUMBER_OF_VALIDATION = 5000\n",
    "# shuffled_indices = np.random.permutation(len(data_list_train))\n",
    "# train_indices = shuffled_indices[NUMBER_OF_VALIDATION:]\n",
    "# val_indices = shuffled_indices[:NUMBER_OF_VALIDATION]\n",
    "\n",
    "data_list_test_part = data_list_test[:NUMBER_OF_VALIDATION]\n",
    "test_dataset = ECFDataset(data_list_test_part)\n",
    "\n",
    "# train_dataset_all = ECFDataset(data_list_train)\n",
    "\n",
    "# train_dataset = torch.utils.data.Subset(train_dataset_all, train_indices)\n",
    "# validation_dataset = torch.utils.data.Subset(train_dataset_all, val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yq9MV8KNUM7T"
   },
   "outputs": [],
   "source": [
    "# store the Subset object\n",
    "# with open('/content/drive/MyDrive/NIST_ECF' + '/validation_subset_pow.pkl', 'wb') as f:\n",
    "#     pickle.dump(validation_dataset, f)\n",
    "\n",
    "# with open('/content/drive/MyDrive/NIST_ECF' + '/train_subset_pow.pkl', 'wb') as f:\n",
    "#     pickle.dump(train_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vrhdjnUS0op1"
   },
   "outputs": [],
   "source": [
    "with open(\"/content/drive/MyDrive/NIST_ECF/validation_subset_pow.pkl\", 'rb') as handle:\n",
    "    validation_dataset  = pickle.load(handle)\n",
    "\n",
    "with open(\"/content/drive/MyDrive/NIST_ECF/train_subset_pow.pkl\", 'rb') as handle:\n",
    "    train_dataset  = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ukr9imea4yOx"
   },
   "outputs": [],
   "source": [
    "def mask_prediction_by_mass(total_mass, raw_prediction, index_shift):\n",
    "    # Zero out predictions to the right of the maximum possible mass.\n",
    "    # input \n",
    "    # anchor_indices: shape (,batch_size) = ex [3,4,5]\n",
    "    #     total_mass = Weights of whole molecule, not only fragment\n",
    "    # data: shape (batch_size, embedding), embedding from GNN in our case\n",
    "    # index_shift: int constant how far can heaviest fragment differ from weight of original molecule\n",
    "    # \n",
    "\n",
    "    data = raw_prediction.type(torch.float64)\n",
    "    \n",
    "    total_mass = torch.round(total_mass).type(torch.int64)\n",
    "    indices = torch.arange(data.shape[-1])[None, ...].to(device)\n",
    "\n",
    "    right_of_total_mass = indices > (\n",
    "            total_mass[..., None] +\n",
    "            index_shift)\n",
    "    return torch.where(right_of_total_mass, torch.zeros_like(data),\n",
    "                        data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s0pJpzsO46pK"
   },
   "outputs": [],
   "source": [
    "def reverse_prediction(total_mass, raw_prediction, index_shift):\n",
    "    # reverse vector by anchor_indices and rest set to zero and make preproessing\n",
    "    # input \n",
    "    # total_mass: shape (,batch_size) = ex [3,4,5]\n",
    "    #     total_mass = Weights of whole molecule, not only fragment\n",
    "    # raw_prediction: shape (batch_size, embedding), embedding from GNN in our case\n",
    "    # index_shift: int constant how far can heaviest fragment differ from weight of original molecule\n",
    "    #     total_mass = feature_dict[fmap_constants.MOLECULE_WEIGHT][..., 0]\n",
    "    \n",
    "    total_mass = torch.round(total_mass).type(torch.int32)\n",
    "    return scatter_by_anchor_indices(\n",
    "        total_mass, raw_prediction, index_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4SyOx-7w46qw"
   },
   "outputs": [],
   "source": [
    "def scatter_by_anchor_indices(anchor_indices, data, index_shift):\n",
    "    # reverse vector by anchor_indices and rest set to zero\n",
    "    # input \n",
    "    # anchor_indices: shape (,batch_size) = ex [3,4,5]\n",
    "    #     total_mass = Weights of whole molecule, not only fragment\n",
    "    # data: shape (batch_size, embedding), embedding from GNN in our case\n",
    "    # index_shift: int constant how far can heaviest fragment differ from weight of original molecule\n",
    "    \n",
    "    index_shift = index_shift\n",
    "    anchor_indices = anchor_indices\n",
    "    data = data.type(torch.float64)\n",
    "    batch_size = data.shape[0]\n",
    "    \n",
    "    num_data_columns = data.shape[-1]\n",
    "    indices = torch.arange(num_data_columns)[None, ...].to(device)\n",
    "    shifted_indices = anchor_indices[..., None] - indices + index_shift\n",
    "    valid_indices = shifted_indices >= 0\n",
    "\n",
    "   \n",
    "\n",
    "    batch_indices = torch.tile(\n",
    "          torch.arange(batch_size)[..., None], [1, num_data_columns]).to(device)\n",
    "    shifted_indices += batch_indices * num_data_columns\n",
    "\n",
    "    shifted_indices = torch.reshape(shifted_indices, [-1])\n",
    "    num_elements = data.shape[0] * data.shape[1]\n",
    "    row_indices = torch.arange(num_elements).to(device)\n",
    "    stacked_indices = torch.stack([row_indices, shifted_indices], axis=1)\n",
    "\n",
    "\n",
    "    lower_batch_boundaries = torch.reshape(batch_indices * num_data_columns, [-1])\n",
    "    upper_batch_boundaries = torch.reshape(((batch_indices + 1) * num_data_columns),\n",
    "                                          [-1])\n",
    "\n",
    "    valid_indices = torch.logical_and(shifted_indices >= lower_batch_boundaries,\n",
    "                                     shifted_indices < upper_batch_boundaries)\n",
    "\n",
    "    stacked_indices = stacked_indices[valid_indices]\n",
    "   \n",
    "    dense_shape = torch.tile(torch.tensor(num_elements)[..., None], [2]).type(torch.int32)\n",
    "\n",
    "    scattering_matrix = torch.sparse.FloatTensor(stacked_indices.type(torch.int64).T,\n",
    "                                                 torch.ones_like(stacked_indices[:, 0]).type(torch.float64),\n",
    "                                                dense_shape.tolist())\n",
    "\n",
    "    flattened_data = torch.reshape(data, [-1])[..., None]\n",
    "    flattened_output = torch.sparse.mm(scattering_matrix, flattened_data)\n",
    "    return torch.reshape(torch.transpose(flattened_output, 0, 1), [-1, num_data_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gmp_OfTcIQC6"
   },
   "outputs": [],
   "source": [
    "def dot_product(true, pred, mass_pow=3, intensity_pow=0.6):\n",
    "    # shape for true and pred is one dimensional array\n",
    "    # pred (number_of_predicted_bins)\n",
    "    # defaul value for mass_pow and intensity_pow is set for Stein dot product\n",
    "    assert true.ndim == pred.ndim and true.ndim == 1\n",
    "    length = true.shape[-1]\n",
    "    mass = np.arange(length).astype(np.float64)\n",
    "        \n",
    "    wl = mass ** mass_pow * pred**intensity_pow\n",
    "    wu = mass ** mass_pow * true**intensity_pow\n",
    "    \n",
    "    pred_weighted_norm = np.sqrt(np.sum((wl**2)))\n",
    "    true_weighted_norm = np.sqrt(np.sum((wu**2)))\n",
    "    \n",
    "    result = np.sum(wl*wu) / (pred_weighted_norm * true_weighted_norm)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gsq4uO92ISJD"
   },
   "outputs": [],
   "source": [
    "def validate_similarities(true, pred, mass_pow, intensity_pow):\n",
    "    # Helper function for validation\n",
    "    similarities = np.array([])\n",
    "    for true_instance, pred_instance in zip(true, pred):\n",
    "        tmp = dot_product(true_instance, pred_instance, mass_pow=mass_pow, intensity_pow=intensity_pow)\n",
    "        \n",
    "        similarities = np.concatenate((similarities, tmp), axis=None)\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YS_I1UxT46sx"
   },
   "outputs": [],
   "source": [
    "class SKIPblock(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, bottleneck_factor=0.5, USE_dropout=True, dropout_rate = 0.25):\n",
    "        super().__init__()\n",
    "        #only need to change shape of the residual if num_channels changes (i.e. in_c != out_c)\n",
    "        #[bs,in_c,seq_length]->conv(1,in_c,out_c)->[bs,out_c,seq_length]\n",
    "        \n",
    "        self.batchNorm1 = nn.BatchNorm1d(in_features)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        if USE_dropout:\n",
    "            self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.hidden1= nn.utils.weight_norm(nn.Linear(in_features, int(hidden_features * bottleneck_factor)),name='weight',dim=0)\n",
    "        \n",
    "        self.batchNorm2 = nn.BatchNorm1d(int(hidden_features * bottleneck_factor))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        if USE_dropout:\n",
    "            self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.hidden2 = nn.utils.weight_norm(nn.Linear(int(hidden_features * bottleneck_factor), in_features),name='weight',dim=0)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        hidden = self.batchNorm1(x)\n",
    "        hidden = self.relu1(hidden)\n",
    "        hidden = self.dropout1(hidden)\n",
    "        hidden = self.hidden1(hidden)\n",
    "\n",
    "        hidden = self.batchNorm2(hidden)\n",
    "        hidden = self.relu2(hidden)\n",
    "        hidden = self.dropout2(hidden)\n",
    "        hidden = self.hidden2(hidden)\n",
    "\n",
    "        hidden = hidden + x\n",
    "\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDnKfiOb11K8"
   },
   "source": [
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jaGDgkn01h3N"
   },
   "outputs": [],
   "source": [
    "class ScaledMSE(nn.Module):\n",
    "    def __init__(self, mass_scale=1.0,\n",
    "                 intensity_pow=0.5,\n",
    "                 pred_eps = 1e-9,\n",
    "                 weight_scheme = None,\n",
    "                 func = 'l2', \n",
    "                 loss_pow = 1, \n",
    "                 invalid_mass_weight = 0.0, \n",
    "                 **kwargs):\n",
    "        super(ScaledMSE, self).__init__()\n",
    "        \n",
    "        self.mass_scale = mass_scale\n",
    "        self.intensity_pow = intensity_pow\n",
    "        self.pred_eps = pred_eps\n",
    "        self.weight_scheme = weight_scheme\n",
    "        self.invalid_mass_weight = invalid_mass_weight\n",
    "        self.loss_pow = loss_pow\n",
    "        self.loss = torch.nn.MSELoss(reduce='none')\n",
    "    \n",
    "    def forward(self, true_spect, pred_spect, **kwargs):\n",
    "        SPECT_N = true_spect.shape[1]\n",
    "        \n",
    "\n",
    "        mw = 1 + torch.arange(SPECT_N).to(true_spect.device) * self.mass_scale\n",
    "        mw = mw.unsqueeze(0)\n",
    "\n",
    "        w = 1\n",
    "\n",
    "        \n",
    "        eps = self.pred_eps\n",
    "        \n",
    "        pred_weighted = (pred_spect+eps)**self.intensity_pow * mw * w\n",
    "        pred_weighted_norm = torch.sqrt((pred_weighted**2).sum(dim=1)).unsqueeze(-1)\n",
    "        \n",
    "        true_weighted = (true_spect+eps)**self.intensity_pow * mw * w\n",
    "        \n",
    "        true_weighted_norm = torch.sqrt((true_weighted**2).sum(dim=1)).unsqueeze(-1)\n",
    "\n",
    "        pred_weighted_normed = pred_weighted / pred_weighted_norm\n",
    "        true_weighted_normed = true_weighted / true_weighted_norm\n",
    "        \n",
    "        \n",
    "        l = self.loss(pred_weighted_normed, true_weighted_normed)\n",
    "\n",
    "        lw = 1+ (true_spect < 0.01).float() * self.invalid_mass_weight\n",
    "        \n",
    "        return ((l*lw)**self.loss_pow).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "72YE8hDr46vc",
    "outputId": "485235e9-fcce-423c-9bc9-fa91236f95b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DENSE_BIG(\n",
      "  (hidden1): Linear(in_features=1024, out_features=2000, bias=True)\n",
      "  (skip1): SKIPblock(\n",
      "    (batchNorm1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout(p=0.2, inplace=False)\n",
      "    (hidden1): Linear(in_features=2000, out_features=1000, bias=True)\n",
      "    (batchNorm2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (dropout2): Dropout(p=0.2, inplace=False)\n",
      "    (hidden2): Linear(in_features=1000, out_features=2000, bias=True)\n",
      "  )\n",
      "  (skip2): SKIPblock(\n",
      "    (batchNorm1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout(p=0.2, inplace=False)\n",
      "    (hidden1): Linear(in_features=2000, out_features=1000, bias=True)\n",
      "    (batchNorm2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (dropout2): Dropout(p=0.2, inplace=False)\n",
      "    (hidden2): Linear(in_features=1000, out_features=2000, bias=True)\n",
      "  )\n",
      "  (skip3): SKIPblock(\n",
      "    (batchNorm1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout(p=0.2, inplace=False)\n",
      "    (hidden1): Linear(in_features=2000, out_features=1000, bias=True)\n",
      "    (batchNorm2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (dropout2): Dropout(p=0.2, inplace=False)\n",
      "    (hidden2): Linear(in_features=1000, out_features=2000, bias=True)\n",
      "  )\n",
      "  (skip4): SKIPblock(\n",
      "    (batchNorm1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout(p=0.2, inplace=False)\n",
      "    (hidden1): Linear(in_features=2000, out_features=1000, bias=True)\n",
      "    (batchNorm2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (dropout2): Dropout(p=0.2, inplace=False)\n",
      "    (hidden2): Linear(in_features=1000, out_features=2000, bias=True)\n",
      "  )\n",
      "  (skip5): SKIPblock(\n",
      "    (batchNorm1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout(p=0.2, inplace=False)\n",
      "    (hidden1): Linear(in_features=2000, out_features=1000, bias=True)\n",
      "    (batchNorm2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (dropout2): Dropout(p=0.2, inplace=False)\n",
      "    (hidden2): Linear(in_features=1000, out_features=2000, bias=True)\n",
      "  )\n",
      "  (skip6): SKIPblock(\n",
      "    (batchNorm1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout(p=0.2, inplace=False)\n",
      "    (hidden1): Linear(in_features=2000, out_features=1000, bias=True)\n",
      "    (batchNorm2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (dropout2): Dropout(p=0.2, inplace=False)\n",
      "    (hidden2): Linear(in_features=1000, out_features=2000, bias=True)\n",
      "  )\n",
      "  (skip7): SKIPblock(\n",
      "    (batchNorm1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout(p=0.2, inplace=False)\n",
      "    (hidden1): Linear(in_features=2000, out_features=1000, bias=True)\n",
      "    (batchNorm2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (dropout2): Dropout(p=0.2, inplace=False)\n",
      "    (hidden2): Linear(in_features=1000, out_features=2000, bias=True)\n",
      "  )\n",
      "  (relu_out_resnet): ReLU()\n",
      "  (forward_prediction): Linear(in_features=2000, out_features=1000, bias=True)\n",
      "  (backward_prediction): Linear(in_features=2000, out_features=1000, bias=True)\n",
      "  (gate): Linear(in_features=2000, out_features=1000, bias=True)\n",
      "  (relu_out): ReLU()\n",
      ")\n",
      "Number of parameters:  36137000\n"
     ]
    }
   ],
   "source": [
    "class DENSE_BIG(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        # Init parent\n",
    "        super(DENSE_BIG, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "\n",
    "        \n",
    "        self.hidden1 = nn.Linear(INPUT_SIZE, EMBEDDING_SIZE)\n",
    "        self.skip1 = SKIPblock(EMBEDDING_SIZE, EMBEDDING_SIZE)\n",
    "        self.skip2 = SKIPblock(EMBEDDING_SIZE, EMBEDDING_SIZE)\n",
    "        self.skip3 = SKIPblock(EMBEDDING_SIZE, EMBEDDING_SIZE)\n",
    "        self.skip4 = SKIPblock(EMBEDDING_SIZE, EMBEDDING_SIZE)\n",
    "        self.skip5 = SKIPblock(EMBEDDING_SIZE, EMBEDDING_SIZE)\n",
    "        self.skip6 = SKIPblock(EMBEDDING_SIZE, EMBEDDING_SIZE)\n",
    "        self.skip7 = SKIPblock(EMBEDDING_SIZE, EMBEDDING_SIZE)\n",
    "        self.relu_out_resnet = nn.ReLU()\n",
    "\n",
    "        self.forward_prediction = Linear(EMBEDDING_SIZE, OUTPUT_SIZE)\n",
    "        self.backward_prediction = Linear(EMBEDDING_SIZE, OUTPUT_SIZE)\n",
    "        self.gate = Linear(EMBEDDING_SIZE, OUTPUT_SIZE)\n",
    "\n",
    "        self.relu_out = nn.ReLU()\n",
    "        \n",
    "\n",
    "    def forward(self, x, total_mass):\n",
    "\n",
    "        hidden = self.hidden1(x)\n",
    "        hidden = self.skip1(hidden)\n",
    "        hidden = self.skip2(hidden)\n",
    "        hidden = self.skip3(hidden)\n",
    "        hidden = self.skip4(hidden)\n",
    "        hidden = self.skip5(hidden)\n",
    "        hidden = self.skip6(hidden)\n",
    "        hidden = self.skip7(hidden)\n",
    "        \n",
    "        hidden = self.relu_out_resnet(hidden)\n",
    "\n",
    "        # Bidirectional layer\n",
    "        # Forward prediction\n",
    "        forward_prediction_hidden = self.forward_prediction(hidden)\n",
    "        forward_prediction_hidden = mask_prediction_by_mass(total_mass, forward_prediction_hidden, MASS_SHIFT)\n",
    "        \n",
    "        # # Backward prediction\n",
    "        backward_prediction_hidden = self.backward_prediction(hidden)\n",
    "        backward_prediction_hidden = reverse_prediction(total_mass, backward_prediction_hidden, MASS_SHIFT)\n",
    "        \n",
    "        # # Gate\n",
    "        gate_hidden = self.gate(hidden)\n",
    "        gate_hidden = F.sigmoid(gate_hidden)\n",
    "\n",
    "        # # Apply a final (linear) classifier.\n",
    "        out = gate_hidden * forward_prediction_hidden + (1. - gate_hidden) * backward_prediction_hidden\n",
    "        out = self.relu_out(out)\n",
    "        \n",
    "        out = out.type(torch.float64)\n",
    "\n",
    "        return out\n",
    "\n",
    "model = DENSE_BIG()\n",
    "MODEL_NAME = \"DENSE_BIG_ECF_POW\"\n",
    "MODEL_SAVE = os.path.join(BASE_DIRECTORY, MODEL_NAME)\n",
    "os.makedirs(MODEL_SAVE, mode=0o777, exist_ok=True)\n",
    "print(model)\n",
    "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SRgbpGu11SPh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exj95-FM46yF"
   },
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "######################################\n",
    "#  LOSS\n",
    "######################################\n",
    "\n",
    "# Adjuted mean squared error\n",
    "loss_fn = ScaledMSE()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)  \n",
    "scheduler = StepLR(optimizer, step_size=100, gamma=0.5)\n",
    "\n",
    "# Use GPU for training\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Wrap data in a data loader\n",
    "\n",
    "NUM_GRAPHS_PER_BATCH = 64\n",
    "\n",
    "\n",
    "loader = DataLoader(train_dataset, \n",
    "                    batch_size=NUM_GRAPHS_PER_BATCH, shuffle=True)\n",
    "\n",
    "validation_loader = DataLoader(validation_dataset, \n",
    "                    batch_size=NUM_GRAPHS_PER_BATCH, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                         batch_size=NUM_GRAPHS_PER_BATCH, shuffle=True)\n",
    "\n",
    "SAVE_EVERY_X_EPOCH = 10\n",
    "REPORT_EVERY_X_EPOCH = 1\n",
    "\n",
    "def train(loader):\n",
    "    # Enumerate over the data\n",
    "    loss_per_batch = np.array([])\n",
    "    for batch in loader:\n",
    "\n",
    "        # Use GPU\n",
    "        x = batch[0].float().to(device)  \n",
    "        molecular_weight = batch[1].to(device)  \n",
    "        y = batch[2].to(device)  \n",
    "\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad() \n",
    "        # Passing the node features and the connection info\n",
    "        pred = model(x,  molecular_weight) \n",
    "        # Calculating the loss and gradients\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()  \n",
    "        # Update using the gradients\n",
    "        optimizer.step()\n",
    "        loss_per_batch = np.concatenate((loss_per_batch, np.array([loss.clone().detach().cpu().numpy()])))\n",
    "    return loss_per_batch\n",
    "\n",
    "print(\"Starting training...\")\n",
    "\n",
    "for epoch in range(0, 300):\n",
    "    scheduler.step()\n",
    "    loss = train(loader)\n",
    "    pred_test_similarity = np.array([])\n",
    "    pred_validation_similarity = np.array([])\n",
    "   \n",
    "    if epoch % REPORT_EVERY_X_EPOCH == 0:\n",
    "        for batch in test_loader:\n",
    "            x = batch[0].float().to(device)  \n",
    "            molecular_weight = batch[1].to(device)  \n",
    "            y = batch[2].to(device) \n",
    "             \n",
    "            pred = model(x, molecular_weight)\n",
    "\n",
    "            batch_similarity = validate_similarities(y.detach().cpu().numpy(),\n",
    "                                  pred.detach().cpu().numpy(),\n",
    "                                  mass_pow=1.0, intensity_pow=0.5)\n",
    "\n",
    "            pred_test_similarity = np.concatenate((pred_test_similarity, batch_similarity))\n",
    "        \n",
    "        for batch in validation_loader:\n",
    "            x = batch[0].float().to(device)  \n",
    "            molecular_weight = batch[1].to(device)  \n",
    "            y = batch[2].to(device) \n",
    "             \n",
    "            pred = model(x, molecular_weight)\n",
    "\n",
    "            batch_similarity = validate_similarities(y.detach().cpu().numpy(),\n",
    "                                  pred.detach().cpu().numpy(),\n",
    "                                  mass_pow=1.0, intensity_pow=0.5)\n",
    "\n",
    "            pred_validation_similarity = np.concatenate((pred_validation_similarity, batch_similarity))\n",
    "            \n",
    "        \n",
    "        print(f\"Epoch {epoch} | Test DotSimilarity is {pred_test_similarity.mean()}\")\n",
    "        print(f\"Epoch {epoch} | Validation DotSimilarity is {pred_validation_similarity.mean()}\")\n",
    "        print(f\"Epoch {epoch} | Train Loss {loss.mean()}\")\n",
    "        print()\n",
    "    \n",
    "    if epoch % SAVE_EVERY_X_EPOCH == 0:\n",
    "        SAVE_PATH = f\"{epoch}.pt\"\n",
    "            \n",
    "        # Save model\n",
    "        torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "        'metadata': {\"loss\" : \"ScaledMSE\",\n",
    "                     \"Dataset\": \"Preprocessed_pow_ECF_small\",\n",
    "                     \"test_similarities\": pred_test_similarity.mean()}\n",
    "        }, os.path.join(MODEL_SAVE, SAVE_PATH))\n",
    "\n",
    "        LOSS_FILE = f\"all_loss_until_{epoch}.output\"\n",
    "        with open(os.path.join(MODEL_SAVE, LOSS_FILE), 'wb') as fid:\n",
    "            pickle.dump(loss.mean(), fid)\n",
    "            fid.close() \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IN25AjJ646zq"
   },
   "outputs": [],
   "source": [
    "from google.colab import runtime\n",
    "runtime.unassign()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
