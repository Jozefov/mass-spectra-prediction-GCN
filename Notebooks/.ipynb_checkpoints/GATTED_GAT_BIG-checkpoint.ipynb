{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "19VGR7iuNrtA",
    "outputId": "3e5e81c4-cecd-4b09-c93a-e9a436a2b426"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting matchms\n",
      "  Downloading matchms-0.18.0-py3-none-any.whl (109 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.6/109.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from matchms) (3.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from matchms) (1.10.1)\n",
      "Collecting sparsestack>=0.4.1\n",
      "  Downloading sparsestack-0.4.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from matchms) (4.9.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from matchms) (3.7.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from matchms) (1.22.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from matchms) (4.65.0)\n",
      "Requirement already satisfied: numba>=0.47 in /usr/local/lib/python3.10/dist-packages (from matchms) (0.56.4)\n",
      "Collecting pickydict>=0.4.0\n",
      "  Downloading pickydict-0.4.0-py3-none-any.whl (6.1 kB)\n",
      "Collecting deprecated\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting pyteomics>=4.2\n",
      "  Downloading pyteomics-4.6-py2.py3-none-any.whl (235 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.1/235.1 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from matchms) (2.27.1)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.47->matchms) (0.39.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.47->matchms) (67.7.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->matchms) (1.14.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matchms) (23.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matchms) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matchms) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matchms) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matchms) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matchms) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matchms) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matchms) (4.39.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->matchms) (3.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->matchms) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->matchms) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->matchms) (2022.12.7)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->matchms) (1.16.0)\n",
      "Installing collected packages: pyteomics, pickydict, deprecated, sparsestack, matchms\n",
      "Successfully installed deprecated-1.2.13 matchms-0.18.0 pickydict-0.4.0 pyteomics-4.6 sparsestack-0.4.1\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting rdkit\n",
      "  Downloading rdkit-2023.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.22.4)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (8.4.0)\n",
      "Installing collected packages: rdkit\n",
      "Successfully installed rdkit-2023.3.1\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting torch_geometric\n",
      "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.10.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.65.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.22.4)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.0.9)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.27.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2022.12.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.2.0)\n",
      "Building wheels for collected packages: torch_geometric\n",
      "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for torch_geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910476 sha256=9da751adea19ae131c8cb11ab7e44fb784fd499c4270e60ac4bb22f77235af9b\n",
      "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
      "Successfully built torch_geometric\n",
      "Installing collected packages: torch_geometric\n",
      "Successfully installed torch_geometric-2.3.1\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pickle5\n",
      "  Downloading pickle5-0.0.11.tar.gz (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.1/132.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: pickle5\n",
      "  Building wheel for pickle5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pickle5: filename=pickle5-0.0.11-cp310-cp310-linux_x86_64.whl size=256427 sha256=150940d7b3ca005be645277614326c20b1ab955d0df0487e85d969990d039e8a\n",
      "  Stored in directory: /root/.cache/pip/wheels/7d/14/ef/4aab19d27fa8e58772be5c71c16add0426acf9e1f64353235c\n",
      "Successfully built pickle5\n",
      "Installing collected packages: pickle5\n",
      "Successfully installed pickle5-0.0.11\n"
     ]
    }
   ],
   "source": [
    "!pip install matchms\n",
    "!pip install rdkit\n",
    "!pip install torch_geometric\n",
    "!pip install pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R7g5yokWN3A4"
   },
   "outputs": [],
   "source": [
    "from matchms.importing import load_from_msp\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "import matchms\n",
    "from matchms import Spectrum\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from rdkit.Chem.rdmolops import GetAdjacencyMatrix\n",
    "\n",
    "# Pytorch and Pytorch Geometric\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F \n",
    "from torch_geometric.nn import GCNConv, TopKPooling, global_mean_pool, GATConv\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xv4GRz3sN3DF",
    "outputId": "1fc1d041-5e5c-46c1-9859-827de6bf6edd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KUXDow5VN3Fe"
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/content/drive/MyDrive/NIST_SMALL\")\n",
    "BASE_DIRECTORY = \"/content/drive/MyDrive/NIST_SMALL\"\n",
    "\n",
    "TEST_DATA_SIZE = 5000\n",
    "OUTPUT_SIZE = 1000\n",
    "INTENSITY_POWER = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use log preprocessing instead o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "feP9PfZGN3Id"
   },
   "outputs": [],
   "source": [
    "\n",
    "with open(\"/content/drive/MyDrive/NIST_SMALL/Preprocessed_test_log_preparation_no_sparse_small.output\", 'rb') as handle:\n",
    "    data_list_test  = pickle.load(handle)\n",
    "\n",
    "# with open(\"/content/drive/MyDrive/NIST_SMALL/Preprocessed_train_log_preparation_no_sparse_small.output\", 'rb') as handle:\n",
    "#    data_list_train  = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "OhOxWRn0R7tq"
   },
   "outputs": [],
   "source": [
    "NUMBER_OF_VALIDATION = 5000\n",
    "# shuffled_indices = np.random.permutation(len(data_list_train))\n",
    "# train_indices = shuffled_indices[NUMBER_OF_VALIDATION:]\n",
    "# val_indices = shuffled_indices[:NUMBER_OF_VALIDATION]\n",
    "\n",
    "test_dataset = data_list_test[:NUMBER_OF_VALIDATION]\n",
    "\n",
    "# validation_dataset = torch.utils.data.Subset(data_list_train, val_indices)\n",
    "# train_dataset = torch.utils.data.Subset(data_list_train, train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EsrB1Zb1X6Ia"
   },
   "outputs": [],
   "source": [
    "# store the Subset object\n",
    "\n",
    "\n",
    "# with open(\"/content/drive/MyDrive/NIST_SMALL/train_subset_log.pkl\", 'wb') as handle:\n",
    "#    pickle.dump(train_dataset, handle)\n",
    "\n",
    "# with open(\"/content/drive/MyDrive/NIST_SMALL/validation_subset_log.pkl\", 'wb') as handle:\n",
    "#    pickle.dump(validation_dataset, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6cVNc5Tx8Vl7"
   },
   "outputs": [],
   "source": [
    "with open(\"/content/drive/MyDrive/NIST_SMALL/train_subset_log.pkl\", 'rb') as handle:\n",
    "    train_dataset = pickle.load(handle)\n",
    "\n",
    "with open(\"/content/drive/MyDrive/NIST_SMALL/validation_subset_log.pkl\", 'rb') as handle:\n",
    "    validation_dataset = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jc1qkxZjR-9D",
    "outputId": "2fce7f43-be31-4079-88ee-6407baff9ae1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "107709\n"
     ]
    }
   ],
   "source": [
    "print(len(validation_dataset))\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "37k73ktnN3LN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n2HgdrizN3O8"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 2000\n",
    "NODE_FEATURES = 50\n",
    "EDGE_EMBEDDING = 10\n",
    "MASS_SHIFT = 5 \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_GuHy_lTN3Rd"
   },
   "outputs": [],
   "source": [
    "def mask_prediction_by_mass(total_mass, raw_prediction, index_shift):\n",
    "    # Zero out predictions to the right of the maximum possible mass.\n",
    "    # input \n",
    "    # anchor_indices: shape (,batch_size) = ex [3,4,5]\n",
    "    #     total_mass = Weights of whole molecule, not only fragment\n",
    "    # data: shape (batch_size, embedding), embedding from GNN in our case\n",
    "    # index_shift: int constant how far can heaviest fragment differ from weight of original molecule\n",
    "    # \n",
    "\n",
    "    data = raw_prediction.type(torch.float64)\n",
    "    \n",
    "    total_mass = torch.round(total_mass).type(torch.int64)\n",
    "    indices = torch.arange(data.shape[-1])[None, ...].to(device)\n",
    "\n",
    "    right_of_total_mass = indices > (\n",
    "            total_mass[..., None] +\n",
    "            index_shift)\n",
    "    return torch.where(right_of_total_mass, torch.zeros_like(data),\n",
    "                        data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dWGGTfcwN3Zb"
   },
   "outputs": [],
   "source": [
    "def dot_product(true, pred, mass_pow=3, intensity_pow=0.6):\n",
    "    # shape for true and pred is one dimensional array\n",
    "    # pred (number_of_predicted_bins)\n",
    "    # defaul value for mass_pow and intensity_pow is set for Stein dot product\n",
    "    assert true.ndim == pred.ndim and true.ndim == 1\n",
    "    length = true.shape[-1]\n",
    "    mass = np.arange(length).astype(np.float64)\n",
    "        \n",
    "    wl = mass ** mass_pow * pred**intensity_pow\n",
    "    wu = mass ** mass_pow * true**intensity_pow\n",
    "    \n",
    "    pred_weighted_norm = np.sqrt(np.sum((wl**2)))\n",
    "    true_weighted_norm = np.sqrt(np.sum((wu**2)))\n",
    "    \n",
    "    result = np.sum(wl*wu) / (pred_weighted_norm * true_weighted_norm)\n",
    "    \n",
    "    if np.isnan(result):\n",
    "        result = 1\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GLuLfl_aN3ce"
   },
   "outputs": [],
   "source": [
    "def validate_similarities(true, pred, mass_pow, intensity_pow):\n",
    "    # Helper function for validation\n",
    "    similarities = np.array([])\n",
    "    for true_instance, pred_instance in zip(true, pred):\n",
    "        tmp = dot_product(true_instance, pred_instance, mass_pow=mass_pow, intensity_pow=intensity_pow)\n",
    "        \n",
    "        similarities = np.concatenate((similarities, tmp), axis=None)\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CmZ00K_WOWpC"
   },
   "outputs": [],
   "source": [
    "class SKIPblock(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, bottleneck_factor=0.5, USE_dropout=True, dropout_rate = 0.2):\n",
    "        super().__init__()\n",
    "        #only need to change shape of the residual if num_channels changes (i.e. in_c != out_c)\n",
    "        #[bs,in_c,seq_length]->conv(1,in_c,out_c)->[bs,out_c,seq_length]\n",
    "        \n",
    "        self.batchNorm1 = nn.BatchNorm1d(in_features)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        if USE_dropout:\n",
    "            self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.hidden1= nn.utils.weight_norm(nn.Linear(in_features, int(hidden_features * bottleneck_factor)),name='weight',dim=0)\n",
    "        \n",
    "        self.batchNorm2 = nn.BatchNorm1d(int(hidden_features * bottleneck_factor))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        if USE_dropout:\n",
    "            self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.hidden2 = nn.utils.weight_norm(nn.Linear(int(hidden_features * bottleneck_factor), in_features),name='weight',dim=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        hidden = self.batchNorm1(x)\n",
    "        hidden = self.relu1(hidden)\n",
    "        hidden = self.dropout1(hidden)\n",
    "        hidden = self.hidden1(hidden)\n",
    "\n",
    "        hidden = self.batchNorm2(hidden)\n",
    "        hidden = self.relu2(hidden)\n",
    "        hidden = self.dropout2(hidden)\n",
    "        hidden = self.hidden2(hidden)\n",
    "\n",
    "        hidden = hidden + x\n",
    "\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H4Es0XtjVffL"
   },
   "outputs": [],
   "source": [
    "class SKIPGAT(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, heads, USE_dropout=True, dropout_rate = 0.1):\n",
    "        super().__init__()\n",
    "        #[bs,in_c,seq_length]->conv(1,in_c,out_c)->[bs,out_c,seq_length]\n",
    "\n",
    "        self.relu1 = nn.ReLU()\n",
    "        if USE_dropout:\n",
    "            self.conv1 = GATConv(in_features, hidden_features, heads=heads, dropout=dropout_rate, edge_dim=EDGE_EMBEDDING)\n",
    "        else:\n",
    "            self.conv1 = GATConv(in_features, hidden_features, heads=heads)\n",
    "        \n",
    "        self.relu2 = nn.ReLU()\n",
    "        if USE_dropout:\n",
    "            self.conv2 = GATConv(hidden_features*heads, int(in_features/heads), heads=heads, dropout=dropout_rate, edge_dim=EDGE_EMBEDDING)\n",
    "        else:\n",
    "            self.conv2 = GATConv(hidden_features*heads, int(in_features/heads), heads=heads)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        \n",
    "        hidden = self.relu1(x)\n",
    "        hidden = self.conv1(hidden, edge_index, edge_weight)\n",
    "        \n",
    "        hidden = self.relu2(hidden)\n",
    "        hidden = self.conv2(hidden, edge_index, edge_weight)\n",
    "        hidden = hidden + x\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aLIWg3UUOqxg"
   },
   "outputs": [],
   "source": [
    "class GLUblock_1D(nn.Module):\n",
    "    def __init__(self, k, in_c, out_c):\n",
    "        super().__init__()\n",
    "\n",
    "        if in_c == out_c:\n",
    "            self.use_proj=0\n",
    "        else:\n",
    "            self.use_proj=1\n",
    "        self.convresid=nn.utils.weight_norm(nn.Conv1d(in_c, out_c, kernel_size=1),name='weight',dim=0)\n",
    "        \n",
    "        self.leftpad = nn.ConstantPad1d((k-1, 0),0.0)\n",
    "      \n",
    "        self.convx1a = nn.utils.weight_norm(nn.Conv1d(in_c, out_c, kernel_size=k),name='weight',dim=0)\n",
    "        self.convx2a = nn.utils.weight_norm(nn.Conv1d(in_c, out_c, kernel_size=k),name='weight',dim=0)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        \n",
    "        if self.use_proj==1:\n",
    "            residual=self.convresid(residual)\n",
    "        x=self.leftpad(x) \n",
    "        \n",
    "        x1 = self.convx1a(x) \n",
    "        x2 = self.convx2a(x)\n",
    "        x2 = torch.sigmoid(x2)\n",
    "        \n",
    "        x=torch.mul(x1,x2)\n",
    "        return x+residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UtkGnXUMOWrc",
    "outputId": "88aff36f-bdd6-46f9-e0be-11a5a71f60c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GATTED_GAT_BIG(\n",
      "  (initial_conv): GATConv(50, 300, heads=4)\n",
      "  (skipgat1): SKIPGAT(\n",
      "    (relu1): ReLU()\n",
      "    (conv1): GATConv(1200, 300, heads=4)\n",
      "    (relu2): ReLU()\n",
      "    (conv2): GATConv(1200, 300, heads=4)\n",
      "  )\n",
      "  (skipgat2): SKIPGAT(\n",
      "    (relu1): ReLU()\n",
      "    (conv1): GATConv(1200, 300, heads=4)\n",
      "    (relu2): ReLU()\n",
      "    (conv2): GATConv(1200, 300, heads=4)\n",
      "  )\n",
      "  (skipgat3): SKIPGAT(\n",
      "    (relu1): ReLU()\n",
      "    (conv1): GATConv(1200, 300, heads=4)\n",
      "    (relu2): ReLU()\n",
      "    (conv2): GATConv(1200, 300, heads=4)\n",
      "  )\n",
      "  (skipgat4): SKIPGAT(\n",
      "    (relu1): ReLU()\n",
      "    (conv1): GATConv(1200, 300, heads=4)\n",
      "    (relu2): ReLU()\n",
      "    (conv2): GATConv(1200, 300, heads=4)\n",
      "  )\n",
      "  (mean_conv): GATConv(1200, 300, heads=4)\n",
      "  (mean_relu): ReLU()\n",
      "  (bottleneck): Linear(in_features=300, out_features=2000, bias=True)\n",
      "  (skip1): SKIPblock(\n",
      "    (batchNorm1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout(p=0.2, inplace=False)\n",
      "    (hidden1): Linear(in_features=2000, out_features=1000, bias=True)\n",
      "    (batchNorm2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (dropout2): Dropout(p=0.2, inplace=False)\n",
      "    (hidden2): Linear(in_features=1000, out_features=2000, bias=True)\n",
      "  )\n",
      "  (skip2): SKIPblock(\n",
      "    (batchNorm1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout(p=0.2, inplace=False)\n",
      "    (hidden1): Linear(in_features=2000, out_features=1000, bias=True)\n",
      "    (batchNorm2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (dropout2): Dropout(p=0.2, inplace=False)\n",
      "    (hidden2): Linear(in_features=1000, out_features=2000, bias=True)\n",
      "  )\n",
      "  (skip3): SKIPblock(\n",
      "    (batchNorm1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout(p=0.2, inplace=False)\n",
      "    (hidden1): Linear(in_features=2000, out_features=1000, bias=True)\n",
      "    (batchNorm2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (dropout2): Dropout(p=0.2, inplace=False)\n",
      "    (hidden2): Linear(in_features=1000, out_features=2000, bias=True)\n",
      "  )\n",
      "  (skip4): SKIPblock(\n",
      "    (batchNorm1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout(p=0.2, inplace=False)\n",
      "    (hidden1): Linear(in_features=2000, out_features=1000, bias=True)\n",
      "    (batchNorm2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (dropout2): Dropout(p=0.2, inplace=False)\n",
      "    (hidden2): Linear(in_features=1000, out_features=2000, bias=True)\n",
      "  )\n",
      "  (skip5): SKIPblock(\n",
      "    (batchNorm1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout(p=0.2, inplace=False)\n",
      "    (hidden1): Linear(in_features=2000, out_features=1000, bias=True)\n",
      "    (batchNorm2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (dropout2): Dropout(p=0.2, inplace=False)\n",
      "    (hidden2): Linear(in_features=1000, out_features=2000, bias=True)\n",
      "  )\n",
      "  (skip6): SKIPblock(\n",
      "    (batchNorm1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout(p=0.2, inplace=False)\n",
      "    (hidden1): Linear(in_features=2000, out_features=1000, bias=True)\n",
      "    (batchNorm2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (dropout2): Dropout(p=0.2, inplace=False)\n",
      "    (hidden2): Linear(in_features=1000, out_features=2000, bias=True)\n",
      "  )\n",
      "  (relu_out_resnet): ReLU()\n",
      "  (bottleneck2): Linear(in_features=2000, out_features=1000, bias=True)\n",
      "  (relu_bottlenec2): ReLU()\n",
      "  (GLUlayers): Sequential(\n",
      "    (0): GLUblock_1D(\n",
      "      (convresid): Conv1d(1, 1, kernel_size=(1,), stride=(1,))\n",
      "      (leftpad): ConstantPad1d(padding=(3, 0), value=0.0)\n",
      "      (convx1a): Conv1d(1, 1, kernel_size=(4,), stride=(1,))\n",
      "      (convx2a): Conv1d(1, 1, kernel_size=(4,), stride=(1,))\n",
      "    )\n",
      "    (1): GLUblock_1D(\n",
      "      (convresid): Conv1d(1, 1, kernel_size=(1,), stride=(1,))\n",
      "      (leftpad): ConstantPad1d(padding=(3, 0), value=0.0)\n",
      "      (convx1a): Conv1d(1, 1, kernel_size=(4,), stride=(1,))\n",
      "      (convx2a): Conv1d(1, 1, kernel_size=(4,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (out): ReLU()\n",
      ")\n",
      "Number of parameters:  39835730\n"
     ]
    }
   ],
   "source": [
    "class GATTED_GAT_BIG(torch.nn.Module):\n",
    "    def __init__(self, kernel_size, number_of_gates, number_of_channels, heads):\n",
    "        super(GATTED_GAT_BIG, self).__init__()\n",
    "        # Init parent\n",
    "        torch.manual_seed(42)\n",
    "\n",
    "        EMBEDDING_SIZE_REDUCED = int(EMBEDDING_SIZE*0.15)\n",
    "        # GCN layers\n",
    "        self.initial_conv = GATConv(NODE_FEATURES, EMBEDDING_SIZE_REDUCED, heads=heads)\n",
    "        self.skipgat1 = SKIPGAT(EMBEDDING_SIZE_REDUCED*heads, EMBEDDING_SIZE_REDUCED, heads=heads)\n",
    "        self.skipgat2 = SKIPGAT(EMBEDDING_SIZE_REDUCED*heads, EMBEDDING_SIZE_REDUCED, heads=heads)\n",
    "        self.skipgat3 = SKIPGAT(EMBEDDING_SIZE_REDUCED*heads, EMBEDDING_SIZE_REDUCED, heads=heads)\n",
    "        self.skipgat4 = SKIPGAT(EMBEDDING_SIZE_REDUCED*heads, EMBEDDING_SIZE_REDUCED, heads=heads)\n",
    "        self.mean_conv = GATConv(EMBEDDING_SIZE_REDUCED*heads, EMBEDDING_SIZE_REDUCED, heads=heads, concat=False)\n",
    "        self.mean_relu = nn.ReLU()\n",
    "    \n",
    "        self.bottleneck = Linear(EMBEDDING_SIZE_REDUCED, EMBEDDING_SIZE)\n",
    "\n",
    "        self.skip1 = SKIPblock(EMBEDDING_SIZE, EMBEDDING_SIZE)\n",
    "        self.skip2 = SKIPblock(EMBEDDING_SIZE, EMBEDDING_SIZE)\n",
    "        self.skip3 = SKIPblock(EMBEDDING_SIZE, EMBEDDING_SIZE)\n",
    "        self.skip4 = SKIPblock(EMBEDDING_SIZE, EMBEDDING_SIZE)\n",
    "        self.skip5 = SKIPblock(EMBEDDING_SIZE, EMBEDDING_SIZE)\n",
    "        self.skip6 = SKIPblock(EMBEDDING_SIZE, EMBEDDING_SIZE)\n",
    "\n",
    "        self.relu_out_resnet = nn.ReLU()\n",
    "        self.bottleneck2 = Linear(EMBEDDING_SIZE, OUTPUT_SIZE)\n",
    "        self.relu_bottlenec2 = nn.ReLU()\n",
    "\n",
    "        self.GLUlayers=self.make_GLU_layers(kernel_size, number_of_channels, number_of_gates)\n",
    "        self.out = nn.ReLU()\n",
    "\n",
    "    def make_GLU_layers(self, kernel_size, num_channels, num_layers):\n",
    "        layers = [GLUblock_1D(kernel_size, num_channels, num_channels) for i in range(num_layers)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "        self.relu_out = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight, total_mass, batch_index):\n",
    "        \n",
    "        hidden = self.initial_conv(x, edge_index, edge_weight)\n",
    "     \n",
    "        # Other Conv layers\n",
    "        hidden = self.skipgat1(hidden, edge_index, edge_weight)\n",
    "        hidden = self.skipgat2(hidden, edge_index, edge_weight)\n",
    "        hidden = self.skipgat3(hidden, edge_index, edge_weight)\n",
    "        hidden = self.skipgat4(hidden, edge_index, edge_weight)\n",
    "        hidden = self.mean_conv(hidden, edge_index, edge_weight)\n",
    "        \n",
    "        hidden = gap(hidden, batch_index)\n",
    "        hidden = self.bottleneck(hidden)\n",
    "\n",
    "        hidden = self.skip1(hidden)\n",
    "        hidden = self.skip2(hidden)\n",
    "        hidden = self.skip3(hidden)\n",
    "        hidden = self.skip4(hidden)\n",
    "        hidden = self.skip5(hidden)\n",
    "        hidden = self.skip6(hidden)\n",
    "        \n",
    "        hidden = self.relu_out_resnet(hidden)\n",
    "        hidden = self.bottleneck2(hidden)\n",
    "        hidden = self.relu_bottlenec2(hidden)\n",
    "     \n",
    "        hidden = torch.unsqueeze(hidden, 1)\n",
    "        # Gatted layers\n",
    "        \n",
    "        hidden = self.GLUlayers(hidden)\n",
    "        \n",
    "        hidden = torch.squeeze(hidden, 1)\n",
    "       \n",
    "        hidden = mask_prediction_by_mass(total_mass, hidden, MASS_SHIFT)\n",
    "        \n",
    "        hidden = self.relu_out_resnet(hidden)\n",
    "        hidden = hidden.type(torch.float64)\n",
    "\n",
    "        return hidden\n",
    "kernel_size = 4\n",
    "number_of_gates = 2\n",
    "number_of_channels = 1\n",
    "heads = 4\n",
    "model = GATTED_GAT_BIG(kernel_size, number_of_gates, number_of_channels, heads)\n",
    "MODEL_NAME = \"GATTED_GAT_BIG\"\n",
    "MODEL_SAVE = os.path.join(BASE_DIRECTORY, MODEL_NAME)\n",
    "os.makedirs(MODEL_SAVE, mode=0o777, exist_ok=True)\n",
    "print(model)\n",
    "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hZaKosTKOWt7",
    "outputId": "233a70fc-12a2-4939-ff72-67bc22014f1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 0 | Test DotSimilarity is 0.6503847904181368\n",
      "Epoch 0 | Validation DotSimilarity is 0.649641616568549\n",
      "Epoch 0 | Train Loss 0.12623972498527528\n",
      "\n",
      "Epoch 1 | Test DotSimilarity is 0.669316363878792\n",
      "Epoch 1 | Validation DotSimilarity is 0.6683424469710735\n",
      "Epoch 1 | Train Loss 0.11350085135469816\n",
      "\n",
      "Epoch 2 | Test DotSimilarity is 0.6786829831046003\n",
      "Epoch 2 | Validation DotSimilarity is 0.6778686016825514\n",
      "Epoch 2 | Train Loss 0.10870193495380313\n",
      "\n",
      "Epoch 3 | Test DotSimilarity is 0.6882847429754814\n",
      "Epoch 3 | Validation DotSimilarity is 0.6871187312194931\n",
      "Epoch 3 | Train Loss 0.10547889939276568\n",
      "\n",
      "Epoch 4 | Test DotSimilarity is 0.6952347333296992\n",
      "Epoch 4 | Validation DotSimilarity is 0.6945869942382629\n",
      "Epoch 4 | Train Loss 0.1026600753923343\n",
      "\n",
      "Epoch 5 | Test DotSimilarity is 0.7025115076576405\n",
      "Epoch 5 | Validation DotSimilarity is 0.701590806669156\n",
      "Epoch 5 | Train Loss 0.10062960683026563\n",
      "\n",
      "Epoch 6 | Test DotSimilarity is 0.7071363698164125\n",
      "Epoch 6 | Validation DotSimilarity is 0.7068548862598345\n",
      "Epoch 6 | Train Loss 0.0986073783025253\n",
      "\n",
      "Epoch 7 | Test DotSimilarity is 0.7108307156055521\n",
      "Epoch 7 | Validation DotSimilarity is 0.7102343542838738\n",
      "Epoch 7 | Train Loss 0.09682525011182552\n",
      "\n",
      "Epoch 8 | Test DotSimilarity is 0.7135580784609407\n",
      "Epoch 8 | Validation DotSimilarity is 0.7134490330272395\n",
      "Epoch 8 | Train Loss 0.09513886721105841\n",
      "\n",
      "Epoch 9 | Test DotSimilarity is 0.7184075401350924\n",
      "Epoch 9 | Validation DotSimilarity is 0.7177749202934665\n",
      "Epoch 9 | Train Loss 0.0937806312607691\n",
      "\n",
      "Epoch 10 | Test DotSimilarity is 0.7201855835261923\n",
      "Epoch 10 | Validation DotSimilarity is 0.71991077204716\n",
      "Epoch 10 | Train Loss 0.09235895545258771\n",
      "\n",
      "Epoch 11 | Test DotSimilarity is 0.7227499173765621\n",
      "Epoch 11 | Validation DotSimilarity is 0.7231495141072277\n",
      "Epoch 11 | Train Loss 0.09116524727910691\n",
      "\n",
      "Epoch 12 | Test DotSimilarity is 0.723958772968551\n",
      "Epoch 12 | Validation DotSimilarity is 0.723322321340215\n",
      "Epoch 12 | Train Loss 0.0901272059491946\n",
      "\n",
      "Epoch 13 | Test DotSimilarity is 0.7258463595602967\n",
      "Epoch 13 | Validation DotSimilarity is 0.7258818432170345\n",
      "Epoch 13 | Train Loss 0.0889261197405286\n",
      "\n",
      "Epoch 14 | Test DotSimilarity is 0.7269892208119966\n",
      "Epoch 14 | Validation DotSimilarity is 0.7276560959292511\n",
      "Epoch 14 | Train Loss 0.08781885631652592\n",
      "\n",
      "Epoch 15 | Test DotSimilarity is 0.7296014854257163\n",
      "Epoch 15 | Validation DotSimilarity is 0.7301766063908226\n",
      "Epoch 15 | Train Loss 0.08680946112089225\n",
      "\n",
      "Epoch 16 | Test DotSimilarity is 0.7308245107978828\n",
      "Epoch 16 | Validation DotSimilarity is 0.7314977855567655\n",
      "Epoch 16 | Train Loss 0.0858805973911448\n",
      "\n",
      "Epoch 17 | Test DotSimilarity is 0.7324420704546969\n",
      "Epoch 17 | Validation DotSimilarity is 0.732305859388178\n",
      "Epoch 17 | Train Loss 0.08498914135990575\n",
      "\n",
      "Epoch 18 | Test DotSimilarity is 0.7345550788698825\n",
      "Epoch 18 | Validation DotSimilarity is 0.7350754304854218\n",
      "Epoch 18 | Train Loss 0.08406030542781147\n",
      "\n",
      "Epoch 19 | Test DotSimilarity is 0.7348854826599891\n",
      "Epoch 19 | Validation DotSimilarity is 0.7352770359470879\n",
      "Epoch 19 | Train Loss 0.08321342692975892\n",
      "\n",
      "Epoch 20 | Test DotSimilarity is 0.7372260760020205\n",
      "Epoch 20 | Validation DotSimilarity is 0.7374096352221943\n",
      "Epoch 20 | Train Loss 0.08244629823518118\n",
      "\n",
      "Epoch 21 | Test DotSimilarity is 0.7361671027077983\n",
      "Epoch 21 | Validation DotSimilarity is 0.7372237051461186\n",
      "Epoch 21 | Train Loss 0.08162564837221697\n",
      "\n",
      "Epoch 22 | Test DotSimilarity is 0.7393316441204076\n",
      "Epoch 22 | Validation DotSimilarity is 0.7397365110459622\n",
      "Epoch 22 | Train Loss 0.08085305369967458\n",
      "\n",
      "Epoch 23 | Test DotSimilarity is 0.7396811089571614\n",
      "Epoch 23 | Validation DotSimilarity is 0.740579115127708\n",
      "Epoch 23 | Train Loss 0.08017404660718577\n",
      "\n",
      "Epoch 24 | Test DotSimilarity is 0.7421553655202751\n",
      "Epoch 24 | Validation DotSimilarity is 0.7432796769173479\n",
      "Epoch 24 | Train Loss 0.07933152813417205\n",
      "\n",
      "Epoch 25 | Test DotSimilarity is 0.7433147749710409\n",
      "Epoch 25 | Validation DotSimilarity is 0.7435128424303914\n",
      "Epoch 25 | Train Loss 0.07851979189731532\n",
      "\n",
      "Epoch 26 | Test DotSimilarity is 0.7451000371576192\n",
      "Epoch 26 | Validation DotSimilarity is 0.7455639376856236\n",
      "Epoch 26 | Train Loss 0.07783103566422261\n",
      "\n",
      "Epoch 27 | Test DotSimilarity is 0.7453861361470683\n",
      "Epoch 27 | Validation DotSimilarity is 0.7461289959184028\n",
      "Epoch 27 | Train Loss 0.07709179465578966\n",
      "\n",
      "Epoch 28 | Test DotSimilarity is 0.7464751841726642\n",
      "Epoch 28 | Validation DotSimilarity is 0.7468155066424993\n",
      "Epoch 28 | Train Loss 0.07632765235217776\n",
      "\n",
      "Epoch 29 | Test DotSimilarity is 0.7479763094930787\n",
      "Epoch 29 | Validation DotSimilarity is 0.7489692073482862\n",
      "Epoch 29 | Train Loss 0.07566666757237474\n",
      "\n",
      "Epoch 30 | Test DotSimilarity is 0.7474147735261698\n",
      "Epoch 30 | Validation DotSimilarity is 0.7484760337064962\n",
      "Epoch 30 | Train Loss 0.07505971102400608\n",
      "\n",
      "Epoch 31 | Test DotSimilarity is 0.7500146060084281\n",
      "Epoch 31 | Validation DotSimilarity is 0.7497680064935597\n",
      "Epoch 31 | Train Loss 0.0743743641091401\n",
      "\n",
      "Epoch 32 | Test DotSimilarity is 0.7496947763627756\n",
      "Epoch 32 | Validation DotSimilarity is 0.7513169532783082\n",
      "Epoch 32 | Train Loss 0.07390152141677407\n",
      "\n",
      "Epoch 33 | Test DotSimilarity is 0.7509430897099466\n",
      "Epoch 33 | Validation DotSimilarity is 0.7511160065198905\n",
      "Epoch 33 | Train Loss 0.07332920864755493\n",
      "\n",
      "Epoch 34 | Test DotSimilarity is 0.7494496770367389\n",
      "Epoch 34 | Validation DotSimilarity is 0.7509029312850607\n",
      "Epoch 34 | Train Loss 0.07283501424562487\n",
      "\n",
      "Epoch 35 | Test DotSimilarity is 0.7506618740161776\n",
      "Epoch 35 | Validation DotSimilarity is 0.7523154398620711\n",
      "Epoch 35 | Train Loss 0.07243205152789696\n",
      "\n",
      "Epoch 36 | Test DotSimilarity is 0.7523025232727814\n",
      "Epoch 36 | Validation DotSimilarity is 0.7528242946202975\n",
      "Epoch 36 | Train Loss 0.07196225916368931\n",
      "\n",
      "Epoch 37 | Test DotSimilarity is 0.7512205899359489\n",
      "Epoch 37 | Validation DotSimilarity is 0.7520289974971109\n",
      "Epoch 37 | Train Loss 0.07148682618927694\n",
      "\n",
      "Epoch 38 | Test DotSimilarity is 0.7525236982284741\n",
      "Epoch 38 | Validation DotSimilarity is 0.7539103704075903\n",
      "Epoch 38 | Train Loss 0.07109157755588857\n",
      "\n",
      "Epoch 39 | Test DotSimilarity is 0.7537041649356646\n",
      "Epoch 39 | Validation DotSimilarity is 0.7537098599595018\n",
      "Epoch 39 | Train Loss 0.07071827032376911\n",
      "\n",
      "Epoch 40 | Test DotSimilarity is 0.7529748808948659\n",
      "Epoch 40 | Validation DotSimilarity is 0.7545959308854161\n",
      "Epoch 40 | Train Loss 0.0703259624200781\n",
      "\n",
      "Epoch 41 | Test DotSimilarity is 0.753696003110867\n",
      "Epoch 41 | Validation DotSimilarity is 0.7549882327840416\n",
      "Epoch 41 | Train Loss 0.06995788626229023\n",
      "\n",
      "Epoch 42 | Test DotSimilarity is 0.753909897674755\n",
      "Epoch 42 | Validation DotSimilarity is 0.7546897123305149\n",
      "Epoch 42 | Train Loss 0.06958097765899027\n",
      "\n",
      "Epoch 43 | Test DotSimilarity is 0.7552039710744147\n",
      "Epoch 43 | Validation DotSimilarity is 0.7562049612426903\n",
      "Epoch 43 | Train Loss 0.06924339079315973\n",
      "\n",
      "Epoch 44 | Test DotSimilarity is 0.7552210782393879\n",
      "Epoch 44 | Validation DotSimilarity is 0.7560430737233781\n",
      "Epoch 44 | Train Loss 0.06886299898145415\n",
      "\n",
      "Epoch 45 | Test DotSimilarity is 0.7551840555500714\n",
      "Epoch 45 | Validation DotSimilarity is 0.7561712951722153\n",
      "Epoch 45 | Train Loss 0.0685261003576793\n",
      "\n",
      "Epoch 46 | Test DotSimilarity is 0.755861318716718\n",
      "Epoch 46 | Validation DotSimilarity is 0.7562611885188265\n",
      "Epoch 46 | Train Loss 0.06829812828794249\n",
      "\n",
      "Epoch 47 | Test DotSimilarity is 0.7549305888214852\n",
      "Epoch 47 | Validation DotSimilarity is 0.7565786548947291\n",
      "Epoch 47 | Train Loss 0.0679154501159893\n",
      "\n",
      "Epoch 48 | Test DotSimilarity is 0.7554898815357551\n",
      "Epoch 48 | Validation DotSimilarity is 0.7565334273034636\n",
      "Epoch 48 | Train Loss 0.06759243065342646\n",
      "\n",
      "Epoch 49 | Test DotSimilarity is 0.7555434421290248\n",
      "Epoch 49 | Validation DotSimilarity is 0.7564790312488882\n",
      "Epoch 49 | Train Loss 0.06732936589540123\n",
      "\n",
      "Epoch 50 | Test DotSimilarity is 0.7564951503547918\n",
      "Epoch 50 | Validation DotSimilarity is 0.7572953688408021\n",
      "Epoch 50 | Train Loss 0.06702132689346903\n",
      "\n",
      "Epoch 51 | Test DotSimilarity is 0.7569678997446272\n",
      "Epoch 51 | Validation DotSimilarity is 0.7571982292646228\n",
      "Epoch 51 | Train Loss 0.06666971427698923\n",
      "\n",
      "Epoch 52 | Test DotSimilarity is 0.7569799218872441\n",
      "Epoch 52 | Validation DotSimilarity is 0.7577587333904044\n",
      "Epoch 52 | Train Loss 0.06652045866581943\n",
      "\n",
      "Epoch 53 | Test DotSimilarity is 0.7573139153374335\n",
      "Epoch 53 | Validation DotSimilarity is 0.757960451338084\n",
      "Epoch 53 | Train Loss 0.0662301853028188\n",
      "\n",
      "Epoch 54 | Test DotSimilarity is 0.7579766469739455\n",
      "Epoch 54 | Validation DotSimilarity is 0.7585103349802226\n",
      "Epoch 54 | Train Loss 0.06590359958877744\n",
      "\n",
      "Epoch 55 | Test DotSimilarity is 0.7586543291142982\n",
      "Epoch 55 | Validation DotSimilarity is 0.7596083891953498\n",
      "Epoch 55 | Train Loss 0.0657045021814503\n",
      "\n",
      "Epoch 56 | Test DotSimilarity is 0.7579153306441226\n",
      "Epoch 56 | Validation DotSimilarity is 0.759474399673193\n",
      "Epoch 56 | Train Loss 0.06544311572844355\n",
      "\n",
      "Epoch 57 | Test DotSimilarity is 0.7581599566087225\n",
      "Epoch 57 | Validation DotSimilarity is 0.7586503005859073\n",
      "Epoch 57 | Train Loss 0.06522296876335361\n",
      "\n",
      "Epoch 58 | Test DotSimilarity is 0.7586091064652175\n",
      "Epoch 58 | Validation DotSimilarity is 0.759708895251487\n",
      "Epoch 58 | Train Loss 0.06497533981547932\n",
      "\n",
      "Epoch 59 | Test DotSimilarity is 0.7584915724297889\n",
      "Epoch 59 | Validation DotSimilarity is 0.7594440286861337\n",
      "Epoch 59 | Train Loss 0.06473673062621005\n",
      "\n",
      "Epoch 60 | Test DotSimilarity is 0.7587343003757478\n",
      "Epoch 60 | Validation DotSimilarity is 0.7596190551056173\n",
      "Epoch 60 | Train Loss 0.06446580579684404\n",
      "\n",
      "Epoch 61 | Test DotSimilarity is 0.7595343812166797\n",
      "Epoch 61 | Validation DotSimilarity is 0.7596451997230369\n",
      "Epoch 61 | Train Loss 0.06429027713128846\n",
      "\n",
      "Epoch 62 | Test DotSimilarity is 0.757827081863814\n",
      "Epoch 62 | Validation DotSimilarity is 0.7594513367246238\n",
      "Epoch 62 | Train Loss 0.06405956610582042\n",
      "\n",
      "Epoch 63 | Test DotSimilarity is 0.7595514510468765\n",
      "Epoch 63 | Validation DotSimilarity is 0.7596934538133968\n",
      "Epoch 63 | Train Loss 0.0638643832406223\n",
      "\n",
      "Epoch 64 | Test DotSimilarity is 0.7602093117958805\n",
      "Epoch 64 | Validation DotSimilarity is 0.7612398729317831\n",
      "Epoch 64 | Train Loss 0.06366395427812402\n",
      "\n",
      "Epoch 65 | Test DotSimilarity is 0.7590342109661329\n",
      "Epoch 65 | Validation DotSimilarity is 0.7597963419631609\n",
      "Epoch 65 | Train Loss 0.06347358144236813\n",
      "\n",
      "Epoch 66 | Test DotSimilarity is 0.7602122460709688\n",
      "Epoch 66 | Validation DotSimilarity is 0.7612065524882664\n",
      "Epoch 66 | Train Loss 0.06325231352590678\n",
      "\n",
      "Epoch 67 | Test DotSimilarity is 0.7593543491978342\n",
      "Epoch 67 | Validation DotSimilarity is 0.760933486687956\n",
      "Epoch 67 | Train Loss 0.06307862196326217\n",
      "\n",
      "Epoch 68 | Test DotSimilarity is 0.7592811285793326\n",
      "Epoch 68 | Validation DotSimilarity is 0.7608183224563231\n",
      "Epoch 68 | Train Loss 0.06287497685094091\n",
      "\n",
      "Epoch 69 | Test DotSimilarity is 0.7612712776860792\n",
      "Epoch 69 | Validation DotSimilarity is 0.7617134961957328\n",
      "Epoch 69 | Train Loss 0.06272370260130808\n",
      "\n",
      "Epoch 70 | Test DotSimilarity is 0.7604558946932763\n",
      "Epoch 70 | Validation DotSimilarity is 0.7607243160737781\n",
      "Epoch 70 | Train Loss 0.0625974735557943\n",
      "\n",
      "Epoch 71 | Test DotSimilarity is 0.7603180959714224\n",
      "Epoch 71 | Validation DotSimilarity is 0.7609944219231349\n",
      "Epoch 71 | Train Loss 0.06242414597005967\n",
      "\n",
      "Epoch 72 | Test DotSimilarity is 0.7604658597433114\n",
      "Epoch 72 | Validation DotSimilarity is 0.7619730957465414\n",
      "Epoch 72 | Train Loss 0.06212578937657852\n",
      "\n",
      "Epoch 73 | Test DotSimilarity is 0.7608239113789783\n",
      "Epoch 73 | Validation DotSimilarity is 0.7616523749632924\n",
      "Epoch 73 | Train Loss 0.06201838811137345\n",
      "\n",
      "Epoch 74 | Test DotSimilarity is 0.7602468322991066\n",
      "Epoch 74 | Validation DotSimilarity is 0.7627305154949593\n",
      "Epoch 74 | Train Loss 0.061855430003788195\n",
      "\n",
      "Epoch 75 | Test DotSimilarity is 0.7610584616064426\n",
      "Epoch 75 | Validation DotSimilarity is 0.7624401965539787\n",
      "Epoch 75 | Train Loss 0.06166534059185892\n",
      "\n",
      "Epoch 76 | Test DotSimilarity is 0.7609817116173452\n",
      "Epoch 76 | Validation DotSimilarity is 0.7621916719084427\n",
      "Epoch 76 | Train Loss 0.06159386891023258\n",
      "\n",
      "Epoch 77 | Test DotSimilarity is 0.7605879982537371\n",
      "Epoch 77 | Validation DotSimilarity is 0.7611081097273777\n",
      "Epoch 77 | Train Loss 0.061383336471625125\n",
      "\n",
      "Epoch 78 | Test DotSimilarity is 0.7611738043214323\n",
      "Epoch 78 | Validation DotSimilarity is 0.7623747919350673\n",
      "Epoch 78 | Train Loss 0.0612294046632299\n",
      "\n",
      "Epoch 79 | Test DotSimilarity is 0.7607654810229253\n",
      "Epoch 79 | Validation DotSimilarity is 0.7630400869894162\n",
      "Epoch 79 | Train Loss 0.061127065649072734\n",
      "\n",
      "Epoch 80 | Test DotSimilarity is 0.7602570782627283\n",
      "Epoch 80 | Validation DotSimilarity is 0.7615856313561908\n",
      "Epoch 80 | Train Loss 0.060908111891197686\n",
      "\n",
      "Epoch 81 | Test DotSimilarity is 0.761314975747827\n",
      "Epoch 81 | Validation DotSimilarity is 0.7632204622713149\n",
      "Epoch 81 | Train Loss 0.060811841419263976\n",
      "\n",
      "Epoch 82 | Test DotSimilarity is 0.7617889432333513\n",
      "Epoch 82 | Validation DotSimilarity is 0.7632926820442382\n",
      "Epoch 82 | Train Loss 0.060687038105263914\n",
      "\n",
      "Epoch 83 | Test DotSimilarity is 0.7621532640189519\n",
      "Epoch 83 | Validation DotSimilarity is 0.763890234688146\n",
      "Epoch 83 | Train Loss 0.06054812443714483\n",
      "\n",
      "Epoch 84 | Test DotSimilarity is 0.7619816783909057\n",
      "Epoch 84 | Validation DotSimilarity is 0.7630447634055552\n",
      "Epoch 84 | Train Loss 0.060346910200399194\n",
      "\n",
      "Epoch 85 | Test DotSimilarity is 0.7623084545343816\n",
      "Epoch 85 | Validation DotSimilarity is 0.7638547512405375\n",
      "Epoch 85 | Train Loss 0.0602395473563727\n",
      "\n",
      "Epoch 86 | Test DotSimilarity is 0.7619905504457525\n",
      "Epoch 86 | Validation DotSimilarity is 0.763156861365808\n",
      "Epoch 86 | Train Loss 0.060177673187104326\n",
      "\n",
      "Epoch 87 | Test DotSimilarity is 0.7617607875552517\n",
      "Epoch 87 | Validation DotSimilarity is 0.7637664590935695\n",
      "Epoch 87 | Train Loss 0.05997622502927509\n",
      "\n",
      "Epoch 88 | Test DotSimilarity is 0.7623489372610435\n",
      "Epoch 88 | Validation DotSimilarity is 0.764502356233687\n",
      "Epoch 88 | Train Loss 0.059844659034731476\n",
      "\n",
      "Epoch 89 | Test DotSimilarity is 0.7626429491391938\n",
      "Epoch 89 | Validation DotSimilarity is 0.7640105761749089\n",
      "Epoch 89 | Train Loss 0.05972062957358218\n",
      "\n",
      "Epoch 90 | Test DotSimilarity is 0.7623683845644333\n",
      "Epoch 90 | Validation DotSimilarity is 0.7634164376480053\n",
      "Epoch 90 | Train Loss 0.05969242432821078\n",
      "\n",
      "Epoch 91 | Test DotSimilarity is 0.761837302778519\n",
      "Epoch 91 | Validation DotSimilarity is 0.7633893826742665\n",
      "Epoch 91 | Train Loss 0.059448892443334664\n",
      "\n",
      "Epoch 92 | Test DotSimilarity is 0.7623780494598408\n",
      "Epoch 92 | Validation DotSimilarity is 0.7636699325993982\n",
      "Epoch 92 | Train Loss 0.05937655408913583\n",
      "\n",
      "Epoch 93 | Test DotSimilarity is 0.7625706472394315\n",
      "Epoch 93 | Validation DotSimilarity is 0.7637246349591317\n",
      "Epoch 93 | Train Loss 0.059191522281775814\n",
      "\n",
      "Epoch 94 | Test DotSimilarity is 0.7629929204542862\n",
      "Epoch 94 | Validation DotSimilarity is 0.7644037072823296\n",
      "Epoch 94 | Train Loss 0.0590805379839934\n",
      "\n",
      "Epoch 95 | Test DotSimilarity is 0.7638425926870359\n",
      "Epoch 95 | Validation DotSimilarity is 0.7657952751780716\n",
      "Epoch 95 | Train Loss 0.05894844333307118\n",
      "\n",
      "Epoch 96 | Test DotSimilarity is 0.7627463349564054\n",
      "Epoch 96 | Validation DotSimilarity is 0.7644455709475093\n",
      "Epoch 96 | Train Loss 0.05879919025594966\n",
      "\n",
      "Epoch 97 | Test DotSimilarity is 0.7632300012095483\n",
      "Epoch 97 | Validation DotSimilarity is 0.7644958566069706\n",
      "Epoch 97 | Train Loss 0.05871625654929515\n",
      "\n",
      "Epoch 98 | Test DotSimilarity is 0.7640556083754309\n",
      "Epoch 98 | Validation DotSimilarity is 0.7650831720255117\n",
      "Epoch 98 | Train Loss 0.05848884688826581\n",
      "\n",
      "Epoch 99 | Test DotSimilarity is 0.7670382333910504\n",
      "Epoch 99 | Validation DotSimilarity is 0.7685660705771036\n",
      "Epoch 99 | Train Loss 0.0562185161683631\n",
      "\n",
      "Epoch 100 | Test DotSimilarity is 0.7662446269565883\n",
      "Epoch 100 | Validation DotSimilarity is 0.7688485200918143\n",
      "Epoch 100 | Train Loss 0.0554555654061596\n",
      "\n",
      "Epoch 101 | Test DotSimilarity is 0.7667693336008379\n",
      "Epoch 101 | Validation DotSimilarity is 0.7681169615002289\n",
      "Epoch 101 | Train Loss 0.055131934449675235\n",
      "\n",
      "Epoch 102 | Test DotSimilarity is 0.7666327142296047\n",
      "Epoch 102 | Validation DotSimilarity is 0.7685389795773783\n",
      "Epoch 102 | Train Loss 0.05491622240683943\n",
      "\n",
      "Epoch 103 | Test DotSimilarity is 0.7671743716050343\n",
      "Epoch 103 | Validation DotSimilarity is 0.7681299827719289\n",
      "Epoch 103 | Train Loss 0.0547485550723819\n",
      "\n",
      "Epoch 104 | Test DotSimilarity is 0.7665372988452956\n",
      "Epoch 104 | Validation DotSimilarity is 0.7683968919778323\n",
      "Epoch 104 | Train Loss 0.054582666604292375\n",
      "\n",
      "Epoch 105 | Test DotSimilarity is 0.7673053988989017\n",
      "Epoch 105 | Validation DotSimilarity is 0.7686357518412834\n",
      "Epoch 105 | Train Loss 0.05448775431984124\n",
      "\n",
      "Epoch 106 | Test DotSimilarity is 0.7668729344335401\n",
      "Epoch 106 | Validation DotSimilarity is 0.7690583711560849\n",
      "Epoch 106 | Train Loss 0.0543548344947526\n",
      "\n",
      "Epoch 107 | Test DotSimilarity is 0.7675539392935335\n",
      "Epoch 107 | Validation DotSimilarity is 0.768953977923802\n",
      "Epoch 107 | Train Loss 0.05421885705018787\n",
      "\n",
      "Epoch 108 | Test DotSimilarity is 0.7680770729045585\n",
      "Epoch 108 | Validation DotSimilarity is 0.7694472149198734\n",
      "Epoch 108 | Train Loss 0.05409190154974013\n",
      "\n",
      "Epoch 109 | Test DotSimilarity is 0.7676491392837359\n",
      "Epoch 109 | Validation DotSimilarity is 0.7692156258078762\n",
      "Epoch 109 | Train Loss 0.05401910958154732\n",
      "\n",
      "Epoch 110 | Test DotSimilarity is 0.7668776121406431\n",
      "Epoch 110 | Validation DotSimilarity is 0.7682572573528308\n",
      "Epoch 110 | Train Loss 0.05390817863341654\n",
      "\n",
      "Epoch 111 | Test DotSimilarity is 0.7671632658753202\n",
      "Epoch 111 | Validation DotSimilarity is 0.7685056078050713\n",
      "Epoch 111 | Train Loss 0.053812781249651685\n",
      "\n",
      "Epoch 112 | Test DotSimilarity is 0.7669236089639817\n",
      "Epoch 112 | Validation DotSimilarity is 0.7689728153381293\n",
      "Epoch 112 | Train Loss 0.05368762299935488\n",
      "\n",
      "Epoch 113 | Test DotSimilarity is 0.7672966500691482\n",
      "Epoch 113 | Validation DotSimilarity is 0.768979041965768\n",
      "Epoch 113 | Train Loss 0.053609588467477334\n",
      "\n",
      "Epoch 114 | Test DotSimilarity is 0.7676346283301377\n",
      "Epoch 114 | Validation DotSimilarity is 0.7690283269923368\n",
      "Epoch 114 | Train Loss 0.05353873201453811\n",
      "\n",
      "Epoch 115 | Test DotSimilarity is 0.768080101426954\n",
      "Epoch 115 | Validation DotSimilarity is 0.7696492288112137\n",
      "Epoch 115 | Train Loss 0.05343925762333299\n",
      "\n",
      "Epoch 116 | Test DotSimilarity is 0.767459973767191\n",
      "Epoch 116 | Validation DotSimilarity is 0.7689814788993558\n",
      "Epoch 116 | Train Loss 0.053352624059767345\n",
      "\n",
      "Epoch 117 | Test DotSimilarity is 0.7675335939338692\n",
      "Epoch 117 | Validation DotSimilarity is 0.7690548662475992\n",
      "Epoch 117 | Train Loss 0.05327012886830341\n",
      "\n",
      "Epoch 118 | Test DotSimilarity is 0.767607367571511\n",
      "Epoch 118 | Validation DotSimilarity is 0.7696733011789043\n",
      "Epoch 118 | Train Loss 0.053159424267448345\n",
      "\n",
      "Epoch 119 | Test DotSimilarity is 0.7675597429396416\n",
      "Epoch 119 | Validation DotSimilarity is 0.7695394465540966\n",
      "Epoch 119 | Train Loss 0.05308591160372097\n",
      "\n",
      "Epoch 120 | Test DotSimilarity is 0.7672053953746623\n",
      "Epoch 120 | Validation DotSimilarity is 0.7696812844465472\n",
      "Epoch 120 | Train Loss 0.053022596335243706\n",
      "\n",
      "Epoch 121 | Test DotSimilarity is 0.7682136319988675\n",
      "Epoch 121 | Validation DotSimilarity is 0.7694338482857047\n",
      "Epoch 121 | Train Loss 0.052958052389501645\n",
      "\n",
      "Epoch 122 | Test DotSimilarity is 0.7675113105466869\n",
      "Epoch 122 | Validation DotSimilarity is 0.7689908172975862\n",
      "Epoch 122 | Train Loss 0.052873655644940565\n",
      "\n",
      "Epoch 123 | Test DotSimilarity is 0.7676724201271844\n",
      "Epoch 123 | Validation DotSimilarity is 0.769077032923358\n",
      "Epoch 123 | Train Loss 0.052795747250955864\n",
      "\n",
      "Epoch 124 | Test DotSimilarity is 0.7678227896410701\n",
      "Epoch 124 | Validation DotSimilarity is 0.7690475230502255\n",
      "Epoch 124 | Train Loss 0.05273842259488096\n",
      "\n",
      "Epoch 125 | Test DotSimilarity is 0.7678638459280566\n",
      "Epoch 125 | Validation DotSimilarity is 0.7697206609130052\n",
      "Epoch 125 | Train Loss 0.05267942744971394\n",
      "\n",
      "Epoch 126 | Test DotSimilarity is 0.7679558286031267\n",
      "Epoch 126 | Validation DotSimilarity is 0.7700161414412869\n",
      "Epoch 126 | Train Loss 0.05256113488100324\n",
      "\n",
      "Epoch 127 | Test DotSimilarity is 0.7677713644800731\n",
      "Epoch 127 | Validation DotSimilarity is 0.7690250757959435\n",
      "Epoch 127 | Train Loss 0.05251822804119209\n",
      "\n",
      "Epoch 128 | Test DotSimilarity is 0.7681161412023982\n",
      "Epoch 128 | Validation DotSimilarity is 0.7695696559604307\n",
      "Epoch 128 | Train Loss 0.05246684251965297\n",
      "\n",
      "Epoch 129 | Test DotSimilarity is 0.7675633788066225\n",
      "Epoch 129 | Validation DotSimilarity is 0.7694507632482124\n",
      "Epoch 129 | Train Loss 0.052372227416434686\n",
      "\n",
      "Epoch 130 | Test DotSimilarity is 0.7687106721434861\n",
      "Epoch 130 | Validation DotSimilarity is 0.7696260246182303\n",
      "Epoch 130 | Train Loss 0.05230703413381424\n",
      "\n",
      "Epoch 131 | Test DotSimilarity is 0.7684382783831386\n",
      "Epoch 131 | Validation DotSimilarity is 0.7694237025978099\n",
      "Epoch 131 | Train Loss 0.052224642084140016\n",
      "\n",
      "Epoch 132 | Test DotSimilarity is 0.7680251953290604\n",
      "Epoch 132 | Validation DotSimilarity is 0.7698138139630014\n",
      "Epoch 132 | Train Loss 0.052168137762977594\n",
      "\n",
      "Epoch 133 | Test DotSimilarity is 0.7681414001788579\n",
      "Epoch 133 | Validation DotSimilarity is 0.7692986683419978\n",
      "Epoch 133 | Train Loss 0.05210834073287103\n",
      "\n",
      "Epoch 134 | Test DotSimilarity is 0.7681307674493908\n",
      "Epoch 134 | Validation DotSimilarity is 0.7697558589710896\n",
      "Epoch 134 | Train Loss 0.052037712316273396\n",
      "\n",
      "Epoch 135 | Test DotSimilarity is 0.768872599180914\n",
      "Epoch 135 | Validation DotSimilarity is 0.7694348382998573\n",
      "Epoch 135 | Train Loss 0.051971365604713916\n",
      "\n",
      "Epoch 136 | Test DotSimilarity is 0.7684191652823398\n",
      "Epoch 136 | Validation DotSimilarity is 0.7698850856499406\n",
      "Epoch 136 | Train Loss 0.05189738200578218\n",
      "\n",
      "Epoch 137 | Test DotSimilarity is 0.7678583046669489\n",
      "Epoch 137 | Validation DotSimilarity is 0.7701663653239913\n",
      "Epoch 137 | Train Loss 0.05188058714541699\n",
      "\n",
      "Epoch 138 | Test DotSimilarity is 0.7682788190724237\n",
      "Epoch 138 | Validation DotSimilarity is 0.7706322549560639\n",
      "Epoch 138 | Train Loss 0.051771429313164016\n",
      "\n",
      "Epoch 139 | Test DotSimilarity is 0.7686461816805964\n",
      "Epoch 139 | Validation DotSimilarity is 0.7702160677445454\n",
      "Epoch 139 | Train Loss 0.05171051851978148\n",
      "\n",
      "Epoch 140 | Test DotSimilarity is 0.7685770375381151\n",
      "Epoch 140 | Validation DotSimilarity is 0.7705236122768343\n",
      "Epoch 140 | Train Loss 0.05170626999177088\n",
      "\n",
      "Epoch 141 | Test DotSimilarity is 0.7684691602866762\n",
      "Epoch 141 | Validation DotSimilarity is 0.7697215582447902\n",
      "Epoch 141 | Train Loss 0.05161052002153416\n",
      "\n",
      "Epoch 142 | Test DotSimilarity is 0.7686672525386373\n",
      "Epoch 142 | Validation DotSimilarity is 0.7694098807451281\n",
      "Epoch 142 | Train Loss 0.05155818948931093\n",
      "\n",
      "Epoch 143 | Test DotSimilarity is 0.7682553331832368\n",
      "Epoch 143 | Validation DotSimilarity is 0.7700492612824812\n",
      "Epoch 143 | Train Loss 0.05150793694071139\n",
      "\n",
      "Epoch 144 | Test DotSimilarity is 0.7689853255243806\n",
      "Epoch 144 | Validation DotSimilarity is 0.7696882372881871\n",
      "Epoch 144 | Train Loss 0.051438719397902496\n",
      "\n",
      "Epoch 145 | Test DotSimilarity is 0.7686537960326727\n",
      "Epoch 145 | Validation DotSimilarity is 0.7701937547217896\n",
      "Epoch 145 | Train Loss 0.051407848505495776\n",
      "\n",
      "Epoch 146 | Test DotSimilarity is 0.7682366360978066\n",
      "Epoch 146 | Validation DotSimilarity is 0.770213464730899\n",
      "Epoch 146 | Train Loss 0.05133227731766664\n",
      "\n",
      "Epoch 147 | Test DotSimilarity is 0.7694542710320964\n",
      "Epoch 147 | Validation DotSimilarity is 0.7702404104945739\n",
      "Epoch 147 | Train Loss 0.05126486694128316\n",
      "\n",
      "Epoch 148 | Test DotSimilarity is 0.768465022848547\n",
      "Epoch 148 | Validation DotSimilarity is 0.7703290295420014\n",
      "Epoch 148 | Train Loss 0.051227351220709476\n",
      "\n",
      "Epoch 149 | Test DotSimilarity is 0.7689599283326332\n",
      "Epoch 149 | Validation DotSimilarity is 0.7703259688884906\n",
      "Epoch 149 | Train Loss 0.05117797520500461\n",
      "\n",
      "Epoch 150 | Test DotSimilarity is 0.7688974703218048\n",
      "Epoch 150 | Validation DotSimilarity is 0.7710471049605174\n",
      "Epoch 150 | Train Loss 0.05112776937619354\n",
      "\n",
      "Epoch 151 | Test DotSimilarity is 0.7682691210945579\n",
      "Epoch 151 | Validation DotSimilarity is 0.7699359287153564\n",
      "Epoch 151 | Train Loss 0.051077047141011106\n",
      "\n",
      "Epoch 152 | Test DotSimilarity is 0.7691243284942386\n",
      "Epoch 152 | Validation DotSimilarity is 0.7704405919098597\n",
      "Epoch 152 | Train Loss 0.05099996653253872\n",
      "\n",
      "Epoch 153 | Test DotSimilarity is 0.7682883918223568\n",
      "Epoch 153 | Validation DotSimilarity is 0.7701815235175492\n",
      "Epoch 153 | Train Loss 0.050952267535998026\n",
      "\n",
      "Epoch 154 | Test DotSimilarity is 0.7689849874769145\n",
      "Epoch 154 | Validation DotSimilarity is 0.7700640394484696\n",
      "Epoch 154 | Train Loss 0.0509121556510789\n",
      "\n",
      "Epoch 155 | Test DotSimilarity is 0.7687211592116069\n",
      "Epoch 155 | Validation DotSimilarity is 0.7700640224599533\n",
      "Epoch 155 | Train Loss 0.05085869810263206\n",
      "\n",
      "Epoch 156 | Test DotSimilarity is 0.7688036450218808\n",
      "Epoch 156 | Validation DotSimilarity is 0.7705176008946122\n",
      "Epoch 156 | Train Loss 0.05081812595005041\n",
      "\n",
      "Epoch 157 | Test DotSimilarity is 0.7686313875405886\n",
      "Epoch 157 | Validation DotSimilarity is 0.7705244530847848\n",
      "Epoch 157 | Train Loss 0.050787304484284625\n",
      "\n",
      "Epoch 158 | Test DotSimilarity is 0.7679736004949209\n",
      "Epoch 158 | Validation DotSimilarity is 0.770067441051853\n",
      "Epoch 158 | Train Loss 0.050676541933679806\n",
      "\n",
      "Epoch 159 | Test DotSimilarity is 0.7689360154325199\n",
      "Epoch 159 | Validation DotSimilarity is 0.7702958618256622\n",
      "Epoch 159 | Train Loss 0.05069241772842675\n",
      "\n",
      "Epoch 160 | Test DotSimilarity is 0.7692737412242318\n",
      "Epoch 160 | Validation DotSimilarity is 0.7706421430164292\n",
      "Epoch 160 | Train Loss 0.05063441733989559\n",
      "\n",
      "Epoch 161 | Test DotSimilarity is 0.7688063113491853\n",
      "Epoch 161 | Validation DotSimilarity is 0.7698738833086117\n",
      "Epoch 161 | Train Loss 0.05056946564601203\n",
      "\n",
      "Epoch 162 | Test DotSimilarity is 0.7686947974648818\n",
      "Epoch 162 | Validation DotSimilarity is 0.7703426677084727\n",
      "Epoch 162 | Train Loss 0.050542556462102976\n",
      "\n",
      "Epoch 163 | Test DotSimilarity is 0.7685870429900677\n",
      "Epoch 163 | Validation DotSimilarity is 0.7701699293275532\n",
      "Epoch 163 | Train Loss 0.0504946158858763\n",
      "\n",
      "Epoch 164 | Test DotSimilarity is 0.7685867266480818\n",
      "Epoch 164 | Validation DotSimilarity is 0.7705023549510948\n",
      "Epoch 164 | Train Loss 0.05044501049613365\n",
      "\n",
      "Epoch 165 | Test DotSimilarity is 0.7684448958067445\n",
      "Epoch 165 | Validation DotSimilarity is 0.7705747341679023\n",
      "Epoch 165 | Train Loss 0.05040466128021078\n",
      "\n",
      "Epoch 166 | Test DotSimilarity is 0.7683967334838421\n",
      "Epoch 166 | Validation DotSimilarity is 0.7704762643271851\n",
      "Epoch 166 | Train Loss 0.05038952236171403\n",
      "\n",
      "Epoch 167 | Test DotSimilarity is 0.7688265228163249\n",
      "Epoch 167 | Validation DotSimilarity is 0.7701789952206303\n",
      "Epoch 167 | Train Loss 0.0503016460213952\n",
      "\n",
      "Epoch 168 | Test DotSimilarity is 0.7686057921064443\n",
      "Epoch 168 | Validation DotSimilarity is 0.7700272151764948\n",
      "Epoch 168 | Train Loss 0.05029480778641772\n",
      "\n",
      "Epoch 169 | Test DotSimilarity is 0.7688848588907778\n",
      "Epoch 169 | Validation DotSimilarity is 0.7700634044250971\n",
      "Epoch 169 | Train Loss 0.05023669711345943\n",
      "\n",
      "Epoch 170 | Test DotSimilarity is 0.7693850103621002\n",
      "Epoch 170 | Validation DotSimilarity is 0.7704675591901714\n",
      "Epoch 170 | Train Loss 0.05019067663539178\n",
      "\n",
      "Epoch 171 | Test DotSimilarity is 0.7689962836051223\n",
      "Epoch 171 | Validation DotSimilarity is 0.7707655808392138\n",
      "Epoch 171 | Train Loss 0.050154069506345475\n",
      "\n",
      "Epoch 172 | Test DotSimilarity is 0.7691316335073036\n",
      "Epoch 172 | Validation DotSimilarity is 0.7704291639647807\n",
      "Epoch 172 | Train Loss 0.0501115561782092\n",
      "\n",
      "Epoch 173 | Test DotSimilarity is 0.7685419710279277\n",
      "Epoch 173 | Validation DotSimilarity is 0.7706377215252147\n",
      "Epoch 173 | Train Loss 0.05007420991467302\n",
      "\n",
      "Epoch 174 | Test DotSimilarity is 0.7687820062327256\n",
      "Epoch 174 | Validation DotSimilarity is 0.770237341692416\n",
      "Epoch 174 | Train Loss 0.05000835255350273\n",
      "\n",
      "Epoch 175 | Test DotSimilarity is 0.7689458891863189\n",
      "Epoch 175 | Validation DotSimilarity is 0.7709050611510945\n",
      "Epoch 175 | Train Loss 0.04999453325815237\n",
      "\n",
      "Epoch 176 | Test DotSimilarity is 0.7689544808930441\n",
      "Epoch 176 | Validation DotSimilarity is 0.7706816300300613\n",
      "Epoch 176 | Train Loss 0.04993437028277924\n",
      "\n",
      "Epoch 177 | Test DotSimilarity is 0.7693702956869894\n",
      "Epoch 177 | Validation DotSimilarity is 0.7705778226700947\n",
      "Epoch 177 | Train Loss 0.04990242385142716\n",
      "\n",
      "Epoch 178 | Test DotSimilarity is 0.7686820652624338\n",
      "Epoch 178 | Validation DotSimilarity is 0.7707141430513066\n",
      "Epoch 178 | Train Loss 0.049854080701096176\n",
      "\n",
      "Epoch 179 | Test DotSimilarity is 0.76878914477904\n",
      "Epoch 179 | Validation DotSimilarity is 0.7703075456582312\n",
      "Epoch 179 | Train Loss 0.049812422144123736\n",
      "\n",
      "Epoch 180 | Test DotSimilarity is 0.768853820209773\n",
      "Epoch 180 | Validation DotSimilarity is 0.7701918016956759\n",
      "Epoch 180 | Train Loss 0.04978780692606572\n",
      "\n",
      "Epoch 181 | Test DotSimilarity is 0.769100939813237\n",
      "Epoch 181 | Validation DotSimilarity is 0.7708275507210406\n",
      "Epoch 181 | Train Loss 0.049745909749036865\n",
      "\n",
      "Epoch 182 | Test DotSimilarity is 0.769007583585524\n",
      "Epoch 182 | Validation DotSimilarity is 0.7707270849184157\n",
      "Epoch 182 | Train Loss 0.04967800844676247\n",
      "\n",
      "Epoch 183 | Test DotSimilarity is 0.7689525693434096\n",
      "Epoch 183 | Validation DotSimilarity is 0.7708215147633914\n",
      "Epoch 183 | Train Loss 0.04964758010928671\n",
      "\n",
      "Epoch 184 | Test DotSimilarity is 0.7689908068942268\n",
      "Epoch 184 | Validation DotSimilarity is 0.7704683764403306\n",
      "Epoch 184 | Train Loss 0.04962820310613229\n",
      "\n",
      "Epoch 185 | Test DotSimilarity is 0.7689812136913506\n",
      "Epoch 185 | Validation DotSimilarity is 0.7708236944848454\n",
      "Epoch 185 | Train Loss 0.04960095729142168\n",
      "\n",
      "Epoch 186 | Test DotSimilarity is 0.7690953876447028\n",
      "Epoch 186 | Validation DotSimilarity is 0.7706362851033695\n",
      "Epoch 186 | Train Loss 0.0495614117734881\n",
      "\n",
      "Epoch 187 | Test DotSimilarity is 0.7689879711833035\n",
      "Epoch 187 | Validation DotSimilarity is 0.7705732340485422\n",
      "Epoch 187 | Train Loss 0.049520259764997174\n",
      "\n",
      "Epoch 188 | Test DotSimilarity is 0.7688478148776072\n",
      "Epoch 188 | Validation DotSimilarity is 0.7704380728598341\n",
      "Epoch 188 | Train Loss 0.04946614466346016\n",
      "\n",
      "Epoch 189 | Test DotSimilarity is 0.769196090107052\n",
      "Epoch 189 | Validation DotSimilarity is 0.7710821778636207\n",
      "Epoch 189 | Train Loss 0.049469264417973446\n",
      "\n",
      "Epoch 190 | Test DotSimilarity is 0.7687839748413712\n",
      "Epoch 190 | Validation DotSimilarity is 0.77071465899227\n",
      "Epoch 190 | Train Loss 0.04942138220402015\n",
      "\n",
      "Epoch 191 | Test DotSimilarity is 0.7685969799491479\n",
      "Epoch 191 | Validation DotSimilarity is 0.7714562765086682\n",
      "Epoch 191 | Train Loss 0.049385986287576934\n",
      "\n",
      "Epoch 192 | Test DotSimilarity is 0.7693158337322822\n",
      "Epoch 192 | Validation DotSimilarity is 0.7707594637915772\n",
      "Epoch 192 | Train Loss 0.0493133307640541\n",
      "\n",
      "Epoch 193 | Test DotSimilarity is 0.7688490993997784\n",
      "Epoch 193 | Validation DotSimilarity is 0.7710622084756041\n",
      "Epoch 193 | Train Loss 0.049297646820082704\n",
      "\n",
      "Epoch 194 | Test DotSimilarity is 0.769344748206244\n",
      "Epoch 194 | Validation DotSimilarity is 0.7709197455670904\n",
      "Epoch 194 | Train Loss 0.04925780060755716\n",
      "\n",
      "Epoch 195 | Test DotSimilarity is 0.7692062391524331\n",
      "Epoch 195 | Validation DotSimilarity is 0.7713650195230348\n",
      "Epoch 195 | Train Loss 0.04923973053564037\n",
      "\n",
      "Epoch 196 | Test DotSimilarity is 0.7692947170307051\n",
      "Epoch 196 | Validation DotSimilarity is 0.7707931340160631\n",
      "Epoch 196 | Train Loss 0.04921607243637028\n",
      "\n",
      "Epoch 197 | Test DotSimilarity is 0.769102302142812\n",
      "Epoch 197 | Validation DotSimilarity is 0.7705106854516023\n",
      "Epoch 197 | Train Loss 0.04916613409891104\n",
      "\n",
      "Epoch 198 | Test DotSimilarity is 0.7690429252851436\n",
      "Epoch 198 | Validation DotSimilarity is 0.7705411749997769\n",
      "Epoch 198 | Train Loss 0.04913051333725661\n",
      "\n",
      "Epoch 199 | Test DotSimilarity is 0.769780865163059\n",
      "Epoch 199 | Validation DotSimilarity is 0.7716587899549935\n",
      "Epoch 199 | Train Loss 0.04813956886703921\n",
      "\n",
      "Epoch 200 | Test DotSimilarity is 0.7701063990567791\n",
      "Epoch 200 | Validation DotSimilarity is 0.7717076225715864\n",
      "Epoch 200 | Train Loss 0.047826544362406784\n",
      "\n",
      "Epoch 201 | Test DotSimilarity is 0.770596014429112\n",
      "Epoch 201 | Validation DotSimilarity is 0.7717559171064307\n",
      "Epoch 201 | Train Loss 0.047690517778431744\n",
      "\n",
      "Epoch 202 | Test DotSimilarity is 0.7699817065193544\n",
      "Epoch 202 | Validation DotSimilarity is 0.7720841934329076\n",
      "Epoch 202 | Train Loss 0.04761094197128402\n",
      "\n",
      "Epoch 203 | Test DotSimilarity is 0.7704909580385348\n",
      "Epoch 203 | Validation DotSimilarity is 0.771468212802468\n",
      "Epoch 203 | Train Loss 0.047514406286373594\n",
      "\n",
      "Epoch 204 | Test DotSimilarity is 0.7703785152106107\n",
      "Epoch 204 | Validation DotSimilarity is 0.7720769358647875\n",
      "Epoch 204 | Train Loss 0.04746300343838156\n",
      "\n",
      "Epoch 205 | Test DotSimilarity is 0.7701078504520097\n",
      "Epoch 205 | Validation DotSimilarity is 0.7716457965124232\n",
      "Epoch 205 | Train Loss 0.047412165831398095\n",
      "\n",
      "Epoch 206 | Test DotSimilarity is 0.7703322157024318\n",
      "Epoch 206 | Validation DotSimilarity is 0.7720645772518884\n",
      "Epoch 206 | Train Loss 0.04735786309430849\n",
      "\n",
      "Epoch 207 | Test DotSimilarity is 0.7703419712808014\n",
      "Epoch 207 | Validation DotSimilarity is 0.7720937637665578\n",
      "Epoch 207 | Train Loss 0.047339524324763134\n",
      "\n",
      "Epoch 208 | Test DotSimilarity is 0.7702834438955971\n",
      "Epoch 208 | Validation DotSimilarity is 0.7722545548599467\n",
      "Epoch 208 | Train Loss 0.04728455858973447\n",
      "\n",
      "Epoch 209 | Test DotSimilarity is 0.7703201097908622\n",
      "Epoch 209 | Validation DotSimilarity is 0.7718473541950932\n",
      "Epoch 209 | Train Loss 0.04724801413852325\n",
      "\n",
      "Epoch 210 | Test DotSimilarity is 0.7703373869978659\n",
      "Epoch 210 | Validation DotSimilarity is 0.7717090643934011\n",
      "Epoch 210 | Train Loss 0.04722746685074817\n",
      "\n",
      "Epoch 211 | Test DotSimilarity is 0.7707147781842669\n",
      "Epoch 211 | Validation DotSimilarity is 0.771797333640529\n",
      "Epoch 211 | Train Loss 0.0471879609116929\n",
      "\n",
      "Epoch 212 | Test DotSimilarity is 0.769495189461352\n",
      "Epoch 212 | Validation DotSimilarity is 0.7721581762389642\n",
      "Epoch 212 | Train Loss 0.047145932797193583\n",
      "\n",
      "Epoch 213 | Test DotSimilarity is 0.7703937982747506\n",
      "Epoch 213 | Validation DotSimilarity is 0.7715433148665712\n",
      "Epoch 213 | Train Loss 0.0471211910136272\n",
      "\n",
      "Epoch 214 | Test DotSimilarity is 0.7699066384345028\n",
      "Epoch 214 | Validation DotSimilarity is 0.7716511283990387\n",
      "Epoch 214 | Train Loss 0.047117549123460646\n",
      "\n",
      "Epoch 215 | Test DotSimilarity is 0.769484504806634\n",
      "Epoch 215 | Validation DotSimilarity is 0.771925355898232\n",
      "Epoch 215 | Train Loss 0.04705903628201949\n",
      "\n",
      "Epoch 216 | Test DotSimilarity is 0.7696613694096838\n",
      "Epoch 216 | Validation DotSimilarity is 0.7715012082430895\n",
      "Epoch 216 | Train Loss 0.04705584834136503\n",
      "\n",
      "Epoch 217 | Test DotSimilarity is 0.7697400968601164\n",
      "Epoch 217 | Validation DotSimilarity is 0.7715621204392004\n",
      "Epoch 217 | Train Loss 0.04701062923053502\n",
      "\n",
      "Epoch 218 | Test DotSimilarity is 0.769591490929298\n",
      "Epoch 218 | Validation DotSimilarity is 0.77187295898073\n",
      "Epoch 218 | Train Loss 0.0469880461270606\n",
      "\n",
      "Epoch 219 | Test DotSimilarity is 0.7702033689429463\n",
      "Epoch 219 | Validation DotSimilarity is 0.7717366458425051\n",
      "Epoch 219 | Train Loss 0.046937140858885375\n",
      "\n",
      "Epoch 220 | Test DotSimilarity is 0.7698187866796272\n",
      "Epoch 220 | Validation DotSimilarity is 0.771725894069873\n",
      "Epoch 220 | Train Loss 0.04694214052356754\n",
      "\n",
      "Epoch 221 | Test DotSimilarity is 0.7700027059388863\n",
      "Epoch 221 | Validation DotSimilarity is 0.7719598027077995\n",
      "Epoch 221 | Train Loss 0.046908663285107906\n",
      "\n",
      "Epoch 222 | Test DotSimilarity is 0.7704692248165662\n",
      "Epoch 222 | Validation DotSimilarity is 0.771749418743296\n",
      "Epoch 222 | Train Loss 0.04686331126531365\n",
      "\n",
      "Epoch 223 | Test DotSimilarity is 0.7697792539504719\n",
      "Epoch 223 | Validation DotSimilarity is 0.7717890679502886\n",
      "Epoch 223 | Train Loss 0.04686111118873038\n",
      "\n",
      "Epoch 224 | Test DotSimilarity is 0.7698745848008058\n",
      "Epoch 224 | Validation DotSimilarity is 0.7719050186356653\n",
      "Epoch 224 | Train Loss 0.04685309958748132\n",
      "\n",
      "Epoch 225 | Test DotSimilarity is 0.7698669322821865\n",
      "Epoch 225 | Validation DotSimilarity is 0.7714397232879583\n",
      "Epoch 225 | Train Loss 0.04681701073259943\n",
      "\n",
      "Epoch 226 | Test DotSimilarity is 0.769904331759466\n",
      "Epoch 226 | Validation DotSimilarity is 0.7716842142548366\n",
      "Epoch 226 | Train Loss 0.04677587656691283\n",
      "\n",
      "Epoch 227 | Test DotSimilarity is 0.7708061163395165\n",
      "Epoch 227 | Validation DotSimilarity is 0.7715399776797841\n",
      "Epoch 227 | Train Loss 0.04677386504150412\n",
      "\n",
      "Epoch 228 | Test DotSimilarity is 0.7703515306810321\n",
      "Epoch 228 | Validation DotSimilarity is 0.7722235243517052\n",
      "Epoch 228 | Train Loss 0.04675052412371864\n",
      "\n",
      "Epoch 229 | Test DotSimilarity is 0.7699665104695992\n",
      "Epoch 229 | Validation DotSimilarity is 0.7720209881680443\n",
      "Epoch 229 | Train Loss 0.0467213482128653\n",
      "\n",
      "Epoch 230 | Test DotSimilarity is 0.7700544029093986\n",
      "Epoch 230 | Validation DotSimilarity is 0.7722585714284101\n",
      "Epoch 230 | Train Loss 0.046689718375995184\n",
      "\n",
      "Epoch 231 | Test DotSimilarity is 0.7702009301443792\n",
      "Epoch 231 | Validation DotSimilarity is 0.7717696801510212\n",
      "Epoch 231 | Train Loss 0.04667810057685812\n",
      "\n",
      "Epoch 232 | Test DotSimilarity is 0.7704778745334162\n",
      "Epoch 232 | Validation DotSimilarity is 0.7716796660858085\n",
      "Epoch 232 | Train Loss 0.04664917336538527\n",
      "\n",
      "Epoch 233 | Test DotSimilarity is 0.7703204000467913\n",
      "Epoch 233 | Validation DotSimilarity is 0.7716492366565074\n",
      "Epoch 233 | Train Loss 0.046624904786711156\n",
      "\n",
      "Epoch 234 | Test DotSimilarity is 0.7699166127788101\n",
      "Epoch 234 | Validation DotSimilarity is 0.7715063979990093\n",
      "Epoch 234 | Train Loss 0.046599835991098584\n",
      "\n",
      "Epoch 235 | Test DotSimilarity is 0.7702114799981704\n",
      "Epoch 235 | Validation DotSimilarity is 0.7718481435435275\n",
      "Epoch 235 | Train Loss 0.04657401459585602\n",
      "\n",
      "Epoch 236 | Test DotSimilarity is 0.7706744547732107\n",
      "Epoch 236 | Validation DotSimilarity is 0.7721727491623387\n",
      "Epoch 236 | Train Loss 0.04654809892041377\n",
      "\n",
      "Epoch 237 | Test DotSimilarity is 0.7699272292316371\n",
      "Epoch 237 | Validation DotSimilarity is 0.7718878702991169\n",
      "Epoch 237 | Train Loss 0.046538687379137314\n",
      "\n",
      "Epoch 238 | Test DotSimilarity is 0.769888717775065\n",
      "Epoch 238 | Validation DotSimilarity is 0.7714577773566184\n",
      "Epoch 238 | Train Loss 0.046519201480858995\n",
      "\n",
      "Epoch 239 | Test DotSimilarity is 0.7704967558867045\n",
      "Epoch 239 | Validation DotSimilarity is 0.7718649318914546\n",
      "Epoch 239 | Train Loss 0.0465003676090888\n",
      "\n",
      "Epoch 240 | Test DotSimilarity is 0.7698607506753581\n",
      "Epoch 240 | Validation DotSimilarity is 0.7710980615869981\n",
      "Epoch 240 | Train Loss 0.046470331947297376\n",
      "\n",
      "Epoch 241 | Test DotSimilarity is 0.7695965485473054\n",
      "Epoch 241 | Validation DotSimilarity is 0.7719909444136381\n",
      "Epoch 241 | Train Loss 0.04646443608323923\n",
      "\n",
      "Epoch 242 | Test DotSimilarity is 0.7700545802657518\n",
      "Epoch 242 | Validation DotSimilarity is 0.7717466209697325\n",
      "Epoch 242 | Train Loss 0.04642290539314649\n",
      "\n",
      "Epoch 243 | Test DotSimilarity is 0.7698063685610175\n",
      "Epoch 243 | Validation DotSimilarity is 0.7716264620364754\n",
      "Epoch 243 | Train Loss 0.04639130526828407\n",
      "\n",
      "Epoch 244 | Test DotSimilarity is 0.7699019380830541\n",
      "Epoch 244 | Validation DotSimilarity is 0.7712791973455824\n",
      "Epoch 244 | Train Loss 0.04638275941269935\n",
      "\n",
      "Epoch 245 | Test DotSimilarity is 0.7696507831202213\n",
      "Epoch 245 | Validation DotSimilarity is 0.7718882151814476\n",
      "Epoch 245 | Train Loss 0.04638319749477079\n",
      "\n",
      "Epoch 246 | Test DotSimilarity is 0.7699864961972778\n",
      "Epoch 246 | Validation DotSimilarity is 0.7718417494810481\n",
      "Epoch 246 | Train Loss 0.046333491358998176\n",
      "\n",
      "Epoch 247 | Test DotSimilarity is 0.7698311703544101\n",
      "Epoch 247 | Validation DotSimilarity is 0.7710247604284243\n",
      "Epoch 247 | Train Loss 0.046320387169662\n",
      "\n",
      "Epoch 248 | Test DotSimilarity is 0.7700602205101091\n",
      "Epoch 248 | Validation DotSimilarity is 0.7718684144923241\n",
      "Epoch 248 | Train Loss 0.04631647635470462\n",
      "\n",
      "Epoch 249 | Test DotSimilarity is 0.7694326108919178\n",
      "Epoch 249 | Validation DotSimilarity is 0.7716603092518238\n",
      "Epoch 249 | Train Loss 0.04628420547699803\n",
      "\n",
      "Epoch 250 | Test DotSimilarity is 0.7693825095829453\n",
      "Epoch 250 | Validation DotSimilarity is 0.7713852114564332\n",
      "Epoch 250 | Train Loss 0.04627978696951344\n",
      "\n",
      "Epoch 251 | Test DotSimilarity is 0.7701340886537682\n",
      "Epoch 251 | Validation DotSimilarity is 0.771274387519682\n",
      "Epoch 251 | Train Loss 0.046254942517209414\n",
      "\n",
      "Epoch 252 | Test DotSimilarity is 0.7699482715654357\n",
      "Epoch 252 | Validation DotSimilarity is 0.7711703787425462\n",
      "Epoch 252 | Train Loss 0.04623201129514418\n",
      "\n",
      "Epoch 253 | Test DotSimilarity is 0.7698995263691614\n",
      "Epoch 253 | Validation DotSimilarity is 0.7709597898742286\n",
      "Epoch 253 | Train Loss 0.04623913560861817\n",
      "\n",
      "Epoch 254 | Test DotSimilarity is 0.7696026272909037\n",
      "Epoch 254 | Validation DotSimilarity is 0.7712365078865392\n",
      "Epoch 254 | Train Loss 0.04620426262334412\n",
      "\n",
      "Epoch 255 | Test DotSimilarity is 0.7697268052468629\n",
      "Epoch 255 | Validation DotSimilarity is 0.7713020415288673\n",
      "Epoch 255 | Train Loss 0.04620003643311472\n",
      "\n",
      "Epoch 256 | Test DotSimilarity is 0.7696719901927476\n",
      "Epoch 256 | Validation DotSimilarity is 0.7709276964806168\n",
      "Epoch 256 | Train Loss 0.04616263963492303\n",
      "\n",
      "Epoch 257 | Test DotSimilarity is 0.7699150046632046\n",
      "Epoch 257 | Validation DotSimilarity is 0.7715938573313164\n",
      "Epoch 257 | Train Loss 0.046159850268657036\n",
      "\n",
      "Epoch 258 | Test DotSimilarity is 0.7699700053027275\n",
      "Epoch 258 | Validation DotSimilarity is 0.7715703220212988\n",
      "Epoch 258 | Train Loss 0.04611730535241641\n",
      "\n",
      "Epoch 259 | Test DotSimilarity is 0.7698033117489073\n",
      "Epoch 259 | Validation DotSimilarity is 0.7712251160925658\n",
      "Epoch 259 | Train Loss 0.04611006554443943\n",
      "\n",
      "Epoch 260 | Test DotSimilarity is 0.7691664944771516\n",
      "Epoch 260 | Validation DotSimilarity is 0.7709435787773248\n",
      "Epoch 260 | Train Loss 0.04608811551117855\n",
      "\n",
      "Epoch 261 | Test DotSimilarity is 0.7689689315805572\n",
      "Epoch 261 | Validation DotSimilarity is 0.7710585785085553\n",
      "Epoch 261 | Train Loss 0.04608686413161276\n",
      "\n",
      "Epoch 262 | Test DotSimilarity is 0.7702801753292838\n",
      "Epoch 262 | Validation DotSimilarity is 0.7715296737194156\n",
      "Epoch 262 | Train Loss 0.04604184510173153\n",
      "\n",
      "Epoch 263 | Test DotSimilarity is 0.769812183035445\n",
      "Epoch 263 | Validation DotSimilarity is 0.7714336920247439\n",
      "Epoch 263 | Train Loss 0.04605830555248867\n",
      "\n",
      "Epoch 264 | Test DotSimilarity is 0.769631560583105\n",
      "Epoch 264 | Validation DotSimilarity is 0.7713926713089087\n",
      "Epoch 264 | Train Loss 0.04600438994046795\n",
      "\n",
      "Epoch 265 | Test DotSimilarity is 0.7699220543661676\n",
      "Epoch 265 | Validation DotSimilarity is 0.7715031262592889\n",
      "Epoch 265 | Train Loss 0.045999472936385406\n",
      "\n",
      "Epoch 266 | Test DotSimilarity is 0.7695239196443515\n",
      "Epoch 266 | Validation DotSimilarity is 0.7713082504676301\n",
      "Epoch 266 | Train Loss 0.045986532108573196\n",
      "\n",
      "Epoch 267 | Test DotSimilarity is 0.7699077995871009\n",
      "Epoch 267 | Validation DotSimilarity is 0.7712317081768956\n",
      "Epoch 267 | Train Loss 0.04597183092819548\n",
      "\n",
      "Epoch 268 | Test DotSimilarity is 0.7698130550732589\n",
      "Epoch 268 | Validation DotSimilarity is 0.7713118970859227\n",
      "Epoch 268 | Train Loss 0.045942463209963286\n",
      "\n",
      "Epoch 269 | Test DotSimilarity is 0.7695196487679299\n",
      "Epoch 269 | Validation DotSimilarity is 0.7719663290683356\n",
      "Epoch 269 | Train Loss 0.04594962979982782\n",
      "\n",
      "Epoch 270 | Test DotSimilarity is 0.7697884189365674\n",
      "Epoch 270 | Validation DotSimilarity is 0.7712096593604315\n",
      "Epoch 270 | Train Loss 0.04592231447988304\n",
      "\n",
      "Epoch 271 | Test DotSimilarity is 0.7701194124108907\n",
      "Epoch 271 | Validation DotSimilarity is 0.7713877703343197\n",
      "Epoch 271 | Train Loss 0.04589819709487963\n",
      "\n",
      "Epoch 272 | Test DotSimilarity is 0.7700228115378818\n",
      "Epoch 272 | Validation DotSimilarity is 0.7721337872419003\n",
      "Epoch 272 | Train Loss 0.045877167505023464\n",
      "\n",
      "Epoch 273 | Test DotSimilarity is 0.769546102736594\n",
      "Epoch 273 | Validation DotSimilarity is 0.7710250558872848\n",
      "Epoch 273 | Train Loss 0.04585521853508183\n",
      "\n",
      "Epoch 274 | Test DotSimilarity is 0.769927348763824\n",
      "Epoch 274 | Validation DotSimilarity is 0.7712068303915479\n",
      "Epoch 274 | Train Loss 0.04584657056413281\n",
      "\n",
      "Epoch 275 | Test DotSimilarity is 0.769944610004865\n",
      "Epoch 275 | Validation DotSimilarity is 0.7713588526147792\n",
      "Epoch 275 | Train Loss 0.04582616597555483\n",
      "\n",
      "Epoch 276 | Test DotSimilarity is 0.7701781284675762\n",
      "Epoch 276 | Validation DotSimilarity is 0.7712672873628122\n",
      "Epoch 276 | Train Loss 0.04580114408006243\n",
      "\n",
      "Epoch 277 | Test DotSimilarity is 0.7691663860045302\n",
      "Epoch 277 | Validation DotSimilarity is 0.7714978261751878\n",
      "Epoch 277 | Train Loss 0.04578296312523932\n",
      "\n",
      "Epoch 278 | Test DotSimilarity is 0.7701971419264079\n",
      "Epoch 278 | Validation DotSimilarity is 0.7718671034368801\n",
      "Epoch 278 | Train Loss 0.045767865367807484\n",
      "\n",
      "Epoch 279 | Test DotSimilarity is 0.7696564264808715\n",
      "Epoch 279 | Validation DotSimilarity is 0.7716922963404601\n",
      "Epoch 279 | Train Loss 0.04575114141598629\n",
      "\n",
      "Epoch 280 | Test DotSimilarity is 0.7701656142748117\n",
      "Epoch 280 | Validation DotSimilarity is 0.7713811440423597\n",
      "Epoch 280 | Train Loss 0.04571862341912058\n",
      "\n",
      "Epoch 281 | Test DotSimilarity is 0.7699150430325298\n",
      "Epoch 281 | Validation DotSimilarity is 0.7717914248597056\n",
      "Epoch 281 | Train Loss 0.04571253789004926\n",
      "\n",
      "Epoch 282 | Test DotSimilarity is 0.7697274419131809\n",
      "Epoch 282 | Validation DotSimilarity is 0.7714089078225849\n",
      "Epoch 282 | Train Loss 0.04570519944930891\n",
      "\n",
      "Epoch 283 | Test DotSimilarity is 0.7703930573702827\n",
      "Epoch 283 | Validation DotSimilarity is 0.7721301835513239\n",
      "Epoch 283 | Train Loss 0.04567162628289139\n",
      "\n",
      "Epoch 284 | Test DotSimilarity is 0.7695046177331314\n",
      "Epoch 284 | Validation DotSimilarity is 0.7718677642348304\n",
      "Epoch 284 | Train Loss 0.04566256838239344\n",
      "\n",
      "Epoch 285 | Test DotSimilarity is 0.7692972441700693\n",
      "Epoch 285 | Validation DotSimilarity is 0.7716186507397927\n",
      "Epoch 285 | Train Loss 0.0456487799372912\n",
      "\n",
      "Epoch 286 | Test DotSimilarity is 0.770071935786184\n",
      "Epoch 286 | Validation DotSimilarity is 0.7714187617076731\n",
      "Epoch 286 | Train Loss 0.04561211349788757\n",
      "\n",
      "Epoch 287 | Test DotSimilarity is 0.7699426917234569\n",
      "Epoch 287 | Validation DotSimilarity is 0.7714491149596288\n",
      "Epoch 287 | Train Loss 0.04562050688257635\n",
      "\n",
      "Epoch 288 | Test DotSimilarity is 0.7699470318936324\n",
      "Epoch 288 | Validation DotSimilarity is 0.7719686374787234\n",
      "Epoch 288 | Train Loss 0.04559577922938241\n",
      "\n",
      "Epoch 289 | Test DotSimilarity is 0.7697169385100849\n",
      "Epoch 289 | Validation DotSimilarity is 0.7711019780180899\n",
      "Epoch 289 | Train Loss 0.045584118147864276\n",
      "\n",
      "Epoch 290 | Test DotSimilarity is 0.7698013089976575\n",
      "Epoch 290 | Validation DotSimilarity is 0.7713831612757786\n",
      "Epoch 290 | Train Loss 0.0455707279323686\n",
      "\n",
      "Epoch 291 | Test DotSimilarity is 0.7698853843492245\n",
      "Epoch 291 | Validation DotSimilarity is 0.771830426986737\n",
      "Epoch 291 | Train Loss 0.04556191625932366\n",
      "\n",
      "Epoch 292 | Test DotSimilarity is 0.7697576135810269\n",
      "Epoch 292 | Validation DotSimilarity is 0.7713909482694083\n",
      "Epoch 292 | Train Loss 0.04554036580749285\n",
      "\n",
      "Epoch 293 | Test DotSimilarity is 0.7700238872642693\n",
      "Epoch 293 | Validation DotSimilarity is 0.7716168304203251\n",
      "Epoch 293 | Train Loss 0.045493860996288334\n",
      "\n",
      "Epoch 294 | Test DotSimilarity is 0.7695262837635006\n",
      "Epoch 294 | Validation DotSimilarity is 0.7711840701423611\n",
      "Epoch 294 | Train Loss 0.04550186925466974\n",
      "\n",
      "Epoch 295 | Test DotSimilarity is 0.7698494280278512\n",
      "Epoch 295 | Validation DotSimilarity is 0.7717011929124445\n",
      "Epoch 295 | Train Loss 0.04549250107569564\n",
      "\n",
      "Epoch 296 | Test DotSimilarity is 0.7701343675217751\n",
      "Epoch 296 | Validation DotSimilarity is 0.7711796266040974\n",
      "Epoch 296 | Train Loss 0.04547123323957154\n",
      "\n",
      "Epoch 297 | Test DotSimilarity is 0.7695074378347168\n",
      "Epoch 297 | Validation DotSimilarity is 0.7712677401988773\n",
      "Epoch 297 | Train Loss 0.04547027910130422\n",
      "\n",
      "Epoch 298 | Test DotSimilarity is 0.7698598378165468\n",
      "Epoch 298 | Validation DotSimilarity is 0.7713505462415815\n",
      "Epoch 298 | Train Loss 0.04544207931094823\n",
      "\n",
      "Epoch 299 | Test DotSimilarity is 0.7699321957081434\n",
      "Epoch 299 | Validation DotSimilarity is 0.7714685862797913\n",
      "Epoch 299 | Train Loss 0.045010378459476176\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "######################################\n",
    "#  LOSS\n",
    "######################################\n",
    "\n",
    "# Root mean squared error\n",
    "loss_fn = torch.nn.HuberLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005) \n",
    "scheduler = StepLR(optimizer, step_size=100, gamma=0.5)\n",
    "\n",
    "# Use GPU for training\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Wrap data in a data loader\n",
    "\n",
    "\n",
    "\n",
    "NUM_GRAPHS_PER_BATCH = 64\n",
    "\n",
    "\n",
    "loader = DataLoader(train_dataset, \n",
    "                    batch_size=NUM_GRAPHS_PER_BATCH, shuffle=True)\n",
    "\n",
    "validation_loader = DataLoader(validation_dataset, \n",
    "                    batch_size=NUM_GRAPHS_PER_BATCH, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                         batch_size=NUM_GRAPHS_PER_BATCH, shuffle=True)\n",
    "SAVE_EVERY_X_EPOCH = 10\n",
    "REPORT_EVERY_X_EPOCH = 1\n",
    "\n",
    "def train(loader):\n",
    "    # Enumerate over the data\n",
    "    loss_per_batch = np.array([])\n",
    "    for batch in loader:\n",
    "        # Use GPU\n",
    "        batch.to(device)  \n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad() \n",
    "        # Passing the node features and the connection info\n",
    "        pred = model(batch.x.float(), batch.edge_index, batch.edge_attr, batch.molecular_weight, batch.batch) \n",
    "        # Calculating the loss and gradients\n",
    "        loss = loss_fn(pred, batch.y)\n",
    "        loss.backward()  \n",
    "        # Update using the gradients\n",
    "        optimizer.step()\n",
    "        loss_per_batch = np.concatenate((loss_per_batch, np.array([loss.clone().detach().cpu().numpy()])))\n",
    "    return loss_per_batch\n",
    "\n",
    "print(\"Starting training...\")\n",
    "\n",
    "for epoch in range(300):\n",
    "    scheduler.step()\n",
    "    loss = train(loader)\n",
    "    pred_test_similarity = np.array([])\n",
    "    pred_validation_similarity = np.array([])\n",
    "   \n",
    "   \n",
    "    if epoch % REPORT_EVERY_X_EPOCH == 0:\n",
    "        for batch in test_loader:\n",
    "            batch.to(device)  \n",
    "            pred = model(batch.x.float(), batch.edge_index, batch.edge_attr, batch.molecular_weight, batch.batch)\n",
    "\n",
    "            batch_similarity = validate_similarities(batch.y.detach().cpu().numpy(),\n",
    "                                  pred.detach().cpu().numpy(),\n",
    "                                  mass_pow=1.0, intensity_pow=0.5)\n",
    "\n",
    "            pred_test_similarity = np.concatenate((pred_test_similarity, batch_similarity))\n",
    "    \n",
    "        for batch in validation_loader:\n",
    "           \n",
    "            batch.to(device)  \n",
    "            pred = model(batch.x.float(), batch.edge_index, batch.edge_attr, batch.molecular_weight, batch.batch)\n",
    "\n",
    "            batch_similarity = validate_similarities(batch.y.detach().cpu().numpy(),\n",
    "                                  pred.detach().cpu().numpy(),\n",
    "                                  mass_pow=1.0, intensity_pow=0.5)\n",
    "\n",
    "            pred_validation_similarity = np.concatenate((pred_validation_similarity, batch_similarity))\n",
    "            \n",
    "        \n",
    "        print(f\"Epoch {epoch} | Test DotSimilarity is {pred_test_similarity.mean()}\")\n",
    "        print(f\"Epoch {epoch} | Validation DotSimilarity is {pred_validation_similarity.mean()}\")\n",
    "        print(f\"Epoch {epoch} | Train Loss {loss.mean()}\")\n",
    "        print()\n",
    "\n",
    "    \n",
    "    if epoch % SAVE_EVERY_X_EPOCH == 0:\n",
    "        SAVE_PATH = f\"{epoch}.pt\"\n",
    "            \n",
    "        # Save model\n",
    "        torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "        'metadata': {\"loss\" : \"HuberLoss\",\n",
    "                     \"Dataset\": \"Preprocessed_test_log_preparation_no_sparse_small\",\n",
    "                     \"test_similarities\": pred_test_similarity.mean()}\n",
    "        }, os.path.join(MODEL_SAVE, SAVE_PATH))\n",
    "\n",
    "        LOSS_FILE = f\"all_loss_until_{epoch}.output\"\n",
    "        with open(os.path.join(MODEL_SAVE, LOSS_FILE), 'wb') as fid:\n",
    "            pickle.dump(loss.mean(), fid)\n",
    "            fid.close() \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W4JXKObSOWw0"
   },
   "outputs": [],
   "source": [
    "from google.colab import runtime\n",
    "runtime.unassign()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
